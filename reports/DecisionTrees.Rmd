---
title: "Proyecto 2"
author: "Rodrigo Mansilla, Javier Chen"
date: "2025-02-25"
output:
  pdf_document:
    latex_engine: xelatex
  html_document:
    df_print: paged
---

```{r setup, include=FALSE , echo = FALSE, warning = FALSE}
library(tidyr)
library(dplyr)
library(ggplot2)
library(rpart)
library(rpart.plot)
library(caret)
library(randomForest)
knitr::opts_chunk$set(
	fig.align = "center",
  out.width = "100%",
	message = FALSE,
	warning = FALSE,
	cache = TRUE,
	out.width = "75%"
)



```


# Introducción

Breve introducción del proyecto y objetivos.

# Carga y Preprocesamiento de Datos

## Carga de datos

```{r}
# Función para ajustar niveles en datos de prueba según datos de entrenamiento
ajustar_niveles <- function(train, test) {
  for (col in names(train)) {
    if (is.factor(train[[col]])) {
      niveles_train <- levels(train[[col]])
      test[[col]] <- factor(test[[col]], levels = niveles_train)
      test[[col]][is.na(test[[col]])] <- niveles_train[which.max(table(train[[col]]))]
    }
  }
  return(test)
}
# Convertir caracteres a factores en train y test
for (col in names(train)){
  if(is.character(train[[col]])){
    train[[col]] <- as.factor(train[[col]])
    test[[col]]  <- as.factor(test[[col]])
  }
}

# Aplicar la función de ajuste

train <- train %>% drop_na()
test  <- ajustar_niveles(train, test)

train <- read.csv("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/data/processed/train_preprocessed.csv")
test <- read.csv("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/data/processed/test_preprocessed.csv")

cat("Dimensiones train:", dim(train), "\n")
cat("Dimensiones test:", dim(test), "\n")


```

## Ajuste de Factores

Función para ajustar los factores y prevenir errores en las predicciones.

```{r}
ajustar_factores <- function(train, test) {
  columnas <- names(train)[sapply(train, is.factor)]
  for (col in columnas) {
    if (col %in% colnames(test)) {
      test[[col]] <- factor(test[[col]], levels = levels(train[[col]]))
      test[[col]][is.na(test[[col]])] <- levels(train[[col]])[which.max(table(train[[col]]))]
    }
  }
  return(test)
}

# Aplicación
train[] <- lapply(train, function(x) if(is.character(x)) as.factor(x) else x)
test[] <- lapply(test, function(x) if(is.character(x)) as.factor(x) else x)

test <- ajustar_factores(train, test)

test_resp <- test$SalePrice
test <- NULL
```

# Exploración inicial de los datos

```{r}
dim(train)
dim(test)
summary(train)
```

## Árboles de Decisión

### Árbol de regresión

```{r tree1, echo = FALSE, warning = FALSE}}
library(rpart)
library(rpart.plot)

modelo_arbol <- rpart(SalePrice ~ ., data = train)
rpart.plot(modelo_arbol)
```

Se determinan las variables más importantes para el modelo. 
#### Predicción con el modelo de árbol de regresión con parámetros por defecto

```{r pred1 , echo = FALSE, warning = FALSE}
# 1. Ajustar niveles de variables categóricas
factor_vars <- names(train_data)[sapply(train_data, is.factor)]
for (var in factor_vars) {
  if (var %in% names(test_data)) {
    # Si en test aparecen niveles nuevos, estos se convertirán en NA
    test_data[[var]] <- factor(test_data[[var]], levels = levels(train_data[[var]]))
  }
}

# 2. Estandarización de variables numéricas
num_vars <- names(train_data)[sapply(train_data, is.numeric)]
for (var in num_vars) {
  media <- mean(train_data[[var]], na.rm = TRUE)
  sd_val <- sd(train_data[[var]], na.rm = TRUE)
  # Estandarizamos el conjunto de entrenamiento
  train_data[[var]] <- (train_data[[var]] - media) / sd_val
  # Estandarizamos el conjunto de prueba usando la media y sd del entrenamiento
  test_data[[var]] <- (test_data[[var]] - media) / sd_val
}

# Ahora ya se pueden realizar las predicciones sin error
pred_reg_test <- predict(modelo_reg_base, newdata = test_data)
rmse_reg_test <- RMSE(pred_reg_test, test_data$SalePrice)
mse_reg_test <- mean((pred_reg_test - test_data$SalePrice)^2)
cat("RMSE del Arbol de Regresion (Modelo Base):", rmse_reg_test, "\n")
cat("MSE del Arbol de Regresion (Modelo Base):", mse_reg_test, "\n")
pred_reg_train <- predict(modelo_reg_base, newdata = train_data)
rmse_reg_train <- RMSE(pred_reg_train, train_data$SalePrice)
cat("RMSE del Arbol de Regresion (Modelo Base) en entrenamiento:", rmse_reg_train, "\n")
mse_reg_train <- mean((pred_reg_train - train_data$SalePrice)^2)
cat("MSE del Arbol de Regresion (Modelo Base) en entrenamiento:", mse_reg_train, "\n")

```

```{r predgraph1, echo = FALSE, warning = FALSE}


plot(test_data$SalePrice, col = "blue",main = "Prediccion vs Real")
points(pred_reg_test, col = "red")
legend("topright", legend = c("Real", "Prediccion"), col = c("blue", "red"), pch = 1)

```
### Árbol de Regresión Tuned

```{r}
controlcv <- trainControl(method = "cv", number = 10)
profundidades <- expand.grid(maxdepth = 2:10)

modelo_arbol_tuned <- train(SalePrice ~ ., data = train,
                            method = "rpart2",
                            tuneGrid = profundidades,
                            trControl = controlcv,
                            metric = "RMSE")

rpart.plot(modelo_arbol_tuned$finalModel)
modelo_arbol_tuned$bestTune

# Predicción tuned
y_pred_tuned <- predict(modelo_arbol_tuned, test)
RMSE_tuned <- caret::RMSE(y_pred_tuned, test$SalePrice)
cat("RMSE Árbol Regresión Tuned:", RMSE_tuned, "\n")
```

## Clasificación por terciles de precios

```{r}
quantiles <- quantile(train$SalePrice, probs = c(0, 0.33, 0.66, 1))
train$PrecioCat <- cut(train$SalePrice, breaks = quantiles,
                       labels = c("Economica", "Intermedia", "Cara"), include.lowest = TRUE)

test$PrecioCat <- cut(test$SalePrice, breaks = quantiles,
                      labels = c("Economica", "Intermedia", "Cara"),
                      include.lowest = TRUE)
```

### Árbol de Clasificación

```{r}
modelo_clas <- rpart(PrecioCat ~ . -SalePrice, data = train, method = "class")
rpart.plot(modelo_clas)

# Evaluación
pred_clas <- predict(modelo_clas, newdata = test, type = "class")
confusionMatrix(pred_clas, test$PrecioCat)
```

### Árbol de Clasificación Tuned

```{r}
modelo_clas_tuned <- train(PrecioCat ~ . -SalePrice, data = train,
                           method = "rpart2",
                           tuneGrid = profundidades,
                           trControl = controlcv,
                           metric = "Accuracy")
rpart.plot(modelo_clas_tuned$finalModel)

# Evaluación
pred_clas_tuned <- predict(modelo_clas_tuned, test)
confusionMatrix(pred_clas_tuned, test$PrecioCat)
```

### Random Forest

```{r}
modelo_rf <- randomForest(PrecioCat ~ . -SalePrice, data = train)

# Evaluación
pred_rf <- predict(modelo_rf, test)
confusionMatrix(pred_rf, test$PrecioCat)
```

# Comparación de modelos

```{r}
resultados <- data.frame(
  Modelo = c("Regresión Lineal", "Árbol Regresión", "Árbol Tuned"),
  RMSE = c(RMSE_lineal, RMSE_arbol, RMSE_tuned)
)
kable(resultados, caption = "Comparación de Modelos de Regresión")

# Comparativa Clasificación
resultados_clas <- data.frame(
  Modelo = c("Árbol Clasificación", "Árbol Clasificación Tuned", "Random Forest"),
  Accuracy = c(
    confusionMatrix(pred_clas, test$PrecioCat)$overall['Accuracy'],
    confusionMatrix(pred_clas_tuned, test$PrecioCat)$overall['Accuracy'],
    confusionMatrix(pred_rf, test$PrecioCat)$overall['Accuracy']
  )
)
kable(resultados, caption = "Comparativa de Modelos de Clasificación")
```

# Conclusiones


---