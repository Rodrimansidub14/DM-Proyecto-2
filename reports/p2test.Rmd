---
title: "Proyecto 2"
author: "Rodrigo Mansilla, Javier Chen"
date: "2025-02-25"
output:
  pdf_document:
    latex_engine: xelatex
  html_document:
    df_print: paged
---

```{r setup, include=FALSE , echo = FALSE, warning = FALSE}
library(tidyverse)
library(knitr)
library(nortest)  # Para ad.test() y lillie.test()
library(patchwork)
library(psych)
library(corrplot)

library(kableExtra)
library(rmarkdown)
library(xfun)
library(tidyverse)      # Manipulación de datos y piping
library(tidyverse)
library(hopkins)
library(fpc)
library(factoextra)
library(ggrepel)
library(GGally)
library(flexclust)
library(data.table)
library(dplyr)
library(cluster)
library(ggplot2)
library(tidyverse)      # Manipulación de datos y piping
library(tidyverse)
library(hopkins)
library(fpc)
library(parallelDist)
library(ggrepel)
library(GGally)
library(flexclust)
library(data.table)
library(dplyr)
library(cluster)
library(ggplot2)
knitr::opts_chunk$set(
	fig.align = "center",
  out.width = "100%",
	message = FALSE,
	warning = FALSE,
	cache = TRUE,
	out.width = "75%"
)



```

# Introducción

# Metodología

## Exploración inicial de Datos

```{r rd, echo = FALSE, warning = FALSE}

# Cargar el dataset (ajusta la ruta si es necesario)
datos <- read.csv("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/data/raw/train.csv", stringsAsFactors = FALSE)
```

### Dimensiones del Dataset

```{r dims, echo = FALSE, warning = FALSE}

num_filas <- nrow(datos)
num_columnas <- ncol(datos)

# Crear un data frame con las métricas
dimensiones <- data.frame(
  Métrica = c("Número de filas", "Número de columnas"),
  Valor = c(num_filas, num_columnas)
)

# Mostrar la tabla de dimensiones usando kable
library(knitr)
kable(dimensiones, caption = "Dimensiones del Dataset")



```

### Primeras filas

```{r head, echo=FALSE, warning=FALSE}

# Seleccionar un subconjunto de columnas (por ejemplo, las primeras 5)
datos_subset <- datos[, 1:10]

# Mostrar las primeras 6 filas
kable(
  head(datos_subset, 6),
  caption = "Primeras 6 filas (5 columnas)"
)%>%
kable_styling(latex_options = "scale_down")

```

### Ultimas filas

```{r tail, echo=FALSE, warning=FALSE}
library(knitr)
# Mostrar las últimas 6 filas
kable(
  tail(datos_subset, 6),
  caption = "Últimas 6 filas (5 columnas)"
) %>%
  kable_styling(latex_options = "scale_down")
```

Observamos que el dataset contiene una complejidad adecuada y es necesaria la limpieza y transformación de datos para poder detectar relaciones, outliers y patrones en los datos.

## Análisis descriptivo y Exploración de Variables

### Estadísticas Descriptivas de variables numéricas

```{r descriptivas, echo = FALSE, warning = FALSE}

library(knitr)
library(knitr)

# Seleccionar las columnas numéricas del dataset 'datos'
numeric_cols <- datos[sapply(datos, is.numeric)]

# Función para calcular las estadísticas descriptivas con nombres de columnas sin "%"
calc_stats <- function(x) {
  c(
    count = sum(!is.na(x)),
    mean  = mean(x, na.rm = TRUE),
    std   = sd(x, na.rm = TRUE),
    min   = min(x, na.rm = TRUE),
    Q1    = quantile(x, 0.25, na.rm = TRUE),
    Median= quantile(x, 0.50, na.rm = TRUE),  # Este valor es la mediana
    Q3    = quantile(x, 0.75, na.rm = TRUE),
    max   = max(x, na.rm = TRUE),
    mediana = median(x, na.rm = TRUE)
  )
}

# Aplicar la función a cada columna numérica y transponer el resultado
resumen_estadistico <- t(sapply(numeric_cols, calc_stats))
resumen_estadistico <- as.data.frame(resumen_estadistico)

# Redondear los valores para mejorar la legibilidad
resumen_estadistico[] <- lapply(resumen_estadistico, function(x) round(x, 2))

# Mostrar el resumen estadístico con kable
kable(resumen_estadistico, caption = "Resumen Estadístico de Variables Numéricas", escape = TRUE)

```

Estas estadísticas descriptivas nos permiten tener una idea general de la distribución de las variables numéricas en el dataset. A oartir de estos datos podemos explorar variables con gran variabilidad y outliers como:

-   **SalePrice:** Es la variable objetivo; analizar su distribución es esencial para detectar sesgos o valores atípicos que puedan afectar modelos predictivos.

-   **GrLivArea, LotArea, X1stFlrSF y TotalBsmtSF**: Estas variables relacionadas con áreas muestran amplios rangos y desviaciones estándar elevadas, lo que indica una variabilidad considerable. Evaluar su distribución ayudará a entender cómo influyen en el precio.

-   **OverallQual y OverallCond**: Son escalas de calidad y condición que, a pesar de ser discretas, pueden tener un impacto directo en el precio.

-   **YearBuilt y YearRemodAdd:** La antigüedad y el año de remodelación pueden explicar cambios en la valoración de las viviendas. Su distribución puede revelar tendencias históricas y patrones de renovación.

-   **LotFrontage y MasVnrArea:** Aunque LotFrontage presenta datos faltantes, es relevante para entender la exposición del lote. MasVnrArea muestra muchos ceros y algunos valores altos, lo que sugiere la presencia de outliers que vale la pena investigar.

-   **GarageArea y GarageCars:** Estas variables relacionadas con el garaje también presentan variabilidad notable y pueden influir en el precio, es útil evaluar si existen distribuciones sesgadas o valores extremos.

### Exploración de variables categóricas

#### Variables relacionadas con la construcción y estructura

```{r catconst1, echo = FALSE, warning = FALSE}

knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/varscat/frecuencia_BldgType.png")


```

```{r catconst2, echo = FALSE, warning = FALSE}

knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/varscat/frecuencia_HouseStyle.png")


```

```{r catconst3, echo = FALSE, warning = FALSE}

knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/varscat/frecuencia_RoofStyle.png")



```

```{r catconst4, echo = FALSE, warning = FALSE}

knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/varscat/frecuencia_RoofMatl.png")



```

```{r catconst5, echo = FALSE, warning = FALSE}


knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/varscat/frecuencia_Foundation.png")



```

Este grupo de variables muestra una mayoría de casas unifamiliares, predominancia en casasde 2 y 1 piso, techos de tipo Gable y materiales de techos CompShg. La mayoría de las casas tienen cimientos de concreto y madera. Estos patrones pueden ser útiles para identificar características comunes en la construcción de las propiedades.

#### Variables relacionadas con el exterior y materiales

```{r catext1, echo = FALSE, warning = FALSE}

knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/varscat/frecuencia_ExterCond.png")

```

```{r catext2, echo = FALSE, warning = FALSE}

knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/varscat/frecuencia_ExterQual.png")

```

```{r catext3, echo = FALSE, warning = FALSE}


knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/varscat/frecuencia_Exterior1st.png")


```

```{r catext4, echo = FALSE, warning = FALSE}


knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/varscat/frecuencia_MasVnrType.png")


```

La mayoría de las casas presentan una condición y calidad exterior promedio, con pocas en estado excelente o deficiente. En las cubiertas exteriores, domina “VinylSd” tanto en la primera como en la segunda capa, seguido a cierta distancia por “MetalSd”, “Wd Sdng” y “HdBoard”. La mampostería vista (MasVnrType) más frecuente es “BrkFace”, con “Stone” como segunda opción. Esto sugiere un mercado residencial donde predomina un nivel de acabado estándar y revestimientos vinílicos o de metal, con menos variedad en acabados de alta o baja calidad.

#### Variables relacionadas con el sótano

```{r catbsm1, echo=FALSE, warning=FALSE}

knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/varscat/frecuencia_BsmtCond.png")



```

```{r catbsm2, echo=FALSE, warning=FALSE}

knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/varscat/frecuencia_BsmtQual.png")


```

```{r catbsm3, echo=FALSE, warning=FALSE}


knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/varscat/frecuencia_BsmtExposure.png")



```

```{r catbsm4, echo=FALSE, warning=FALSE}

knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/varscat/frecuencia_BsmtFinType1.png")



```

```{r catbsm5, echo=FALSE, warning=FALSE}

knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/varscat/frecuencia_BsmtFinType2.png")


```

La mayoría de los sótanos están en condición “TA” y calidad “TA” o “Gd”, con pocos casos “Ex” o “Fa”. La exposición del sótano suele ser “No” (sin exposición), aunque también hay un grupo con “Gd”, “Mn” y “Av”. Para la terminación del sótano, “GLQ” y “Unf” predominan en BsmtFinType1, mientras que “Unf” es casi absoluto en BsmtFinType2, indicando que muchos sótanos adicionales están sin terminar o tienen acabados básicos.

#### Variables relacionadas con el garaje

```{r catgrg1, echo=FALSE, warning=FALSE}
knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/varscat/frecuencia_GarageType.png")



```

```{r catgrg2, echo=FALSE, warning=FALSE}

knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/varscat/frecuencia_GarageFinish.png")

```

```{r catgrg3, echo=FALSE, warning=FALSE}

knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/varscat/frecuencia_GarageCond.png")

```

```{r catgrg4, echo=FALSE, warning=FALSE}

knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/varscat/frecuencia_GarageQual.png")

```

La mayoría de las casas tienen garajes adjuntos, seguidos por garajes separados y sin garaje. En cuanto al acabado del garaje, predominan los garajes sin acabado o con acabado de calidad estándar. La calidad y condición del garaje tienden a ser promedio, con pocos casos en los extremos. Estos patrones sugieren que la mayoría de las propiedades tienen garajes estándar o básicos, lo que puede influir en el precio de venta.

#### Variables relacionadas con calefacción y electricidad

```{r catheat1, echo=FALSE, warning=FALSE}
knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/varscat/frecuencia_Heating.png")


```

```{r catheat2, echo=FALSE, warning=FALSE}
knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/varscat/frecuencia_HeatingQC.png")


```

```{r catheat3, echo=FALSE, warning=FALSE}
knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/varscat/frecuencia_Electrical.png")


```

```{r catheat4, echo=FALSE, warning=FALSE}
knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/varscat/frecuencia_CentralAir.png")


```

La mayoría de las casas tienen calefacción estándar (GasA) y calidad promedio (TA). La electricidad es principalmente SBrkr, con algunos casos de FuseA y FuseF. La mayoría de las casas tienen aire acondicionado central, lo que sugiere un nivel de comodidad y eficiencia energética estándar en la mayoría de las propiedades.

#### Variables relacionadas con la ubicación del terreno

```{r catterr1, echo=FALSE, warning=FALSE}

knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/varscat/frecuencia_LandContour.png")


```

```{r catterr2, echo=FALSE, warning=FALSE}

knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/varscat/frecuencia_LandSlope.png")


```

```{r catterr3, echo=FALSE, warning=FALSE}

knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/varscat/frecuencia_LotConfig.png")


```

```{r catterr4, echo=FALSE, warning=FALSE}

knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/varscat/frecuencia_LotShape.png")


```

La mayoría de las propiedades tienen terrenos planos o ligeramente inclinados, con configuraciones de lote internas y formas regulares. Estos patrones sugieren que la mayoría de las propiedades están en áreas urbanas o suburbanas, con lotes estándar y fácil acceso a servicios y vías de comunicación.

#### Variables relacionadas con vecindario y accesibilidad

```{r catnbhd1, echo=FALSE, warning=FALSE}
knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/varscat/frecuencia_Alley.png")


```

```{r catnbhd2, echo=FALSE, warning=FALSE}
knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/varscat/frecuencia_Neighborhood.png")



```

```{r catnbhd3, echo=FALSE, warning=FALSE}
knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/varscat/frecuencia_Street.png")


```

```{r catnbhd4, echo=FALSE, warning=FALSE}
knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/varscat/frecuencia_PavedDrive.png")



```

La mayoría de las propiedades tienen acceso por calle pavimentada y no tienen acceso a callejón. Los vecindarios más comunes son NAmes, CollgCr y OldTown, lo que sugiere una concentración en áreas urbanas o suburbanas. La mayoría de las propiedades tienen acceso pavimentado, lo que indica una buena accesibilidad a las vías principales.

#### Variables relacionadas con seguridad y condiciones

```{r catsafty1, echo=FALSE, warning=FALSE}
knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/varscat/frecuencia_SaleType.png")


```

```{r catsafty2, echo=FALSE, warning=FALSE}

knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/varscat/frecuencia_SaleCondition.png")


```

```{r catsafty3, echo=FALSE, warning=FALSE}

knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/varscat/frecuencia_Functional.png")

```

```{r catsafty4, echo=FALSE, warning=FALSE}

knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/varscat/frecuencia_FireplaceQu.png")


```

```{r catsafty5, echo=FALSE, warning=FALSE}

knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/varscat/frecuencia_Fence.png")

```

La mayoría de las propiedades se venden bajo condiciones normales y tienen funcionalidad típica. La calidad de la chimenea es promedio, con pocos casos en los extremos. La mayoría de las propiedades no tienen cercas, lo que sugiere una baja preocupación por la seguridad o privacidad en el vecindario.

### Visualización de Variables Numéricas

```{r SalePrice, echo=FALSE, warning=FALSE}
knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/varsnum/distribucion_SalePrice.png")



```

```{r SalePrice2, echo=FALSE, warning=FALSE}
knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/outliers/boxplot_SalePrice.png")


```

Siendo esta la variable objetivo,observamos una distribución sesgada a la derecha, Esta asimetría puede afectar métodos estadísticos que asumen distribuciones normales. Observamos outliers en la parte superior de la distribución, lo que sugiere la presencia de propiedades muy caras que pueden afectar la predicción de precios.

-   **Boxplot:** Se aprecia que la mayoría de los precios se concentran en un rango intercuartílico entre 130,000 y 210,000 dólares, pero existen varios puntos extremos en la cola superior. Esto indica la presencia de propiedades con precios significativamente más altos.

-   **Histograma** **con curva de densidad**: La distribución se observa sesgada a la derecha, lo que se confirma por la diferencia entre la mediana y la media. Esto sugiere que, para algunos análisis o modelado, podría ser útil aplicar una transformación para aproximar una distribución normal.

#### Variables Numéricas Relacionadas con Áreas y Calidad

```{r GrLivArea, echo=FALSE, warning=FALSE}
knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/varsnum/distribucion_GrLivArea.png")


```

```{r GrLivArea2, echo=FALSE, warning=FALSE}
knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/outliers/boxplot_GrLivArea.png")


```

```{r LotArea, echo=FALSE, warning=FALSE}
knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/varsnum/distribucion_LotArea.png")


```

```{r LotArea2, echo=FALSE, warning=FALSE}
knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/outliers/boxplot_LotArea.png")


```

```{r X1stFlrSF, echo=FALSE, warning=FALSE}
knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/varsnum/distribucion_1stFlrSF.png")


```

```{r X1stFlrSF2, echo=FALSE, warning=FALSE}
knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/outliers/boxplot_1stFlrSF.png")


```

```{r TotalBsmtSF, echo=FALSE, warning=FALSE}

knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/varsnum/distribucion_TotalBsmtSF.png")


```

```{r TotalBsmtSF2, echo=FALSE, warning=FALSE}

knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/outliers/boxplot_TotalBsmtSF.png")


```

**GrLivArea, LotArea, X1stFlrSF y TotalBsmtSF:**

Los gráficos confirman que las variables de área tienden a ser **altamente asimétricas** y presentan **outliers**. Esto será fundamental al momento de construir modelos predictivos y al realizar inferencias estadísticas, ya que puede ser necesario **transformar** o **estratificar** estas variables para obtener resultados más confiables.

#### Variables Numéricas Relacionadas con Calidad y Años

```{r OverallQual, echo=FALSE, warning=FALSE}


knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/varsnum/distribucion_OverallQual.png")


```

```{r OverallQual2, echo=FALSE, warning=FALSE}


knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/outliers/boxplot_OverallQual.png")


```

-   Valores entre 1 y 10.

-   Mayoría entre 5 y 7.

-   Pico alrededor de 5-6.

-   Pocos valores en los extremos.

```{r OverallCond, echo=FALSE, warning=FALSE}
knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/varsnum/distribucion_OverallCond.png")


```

```{r OverallCond2, echo=FALSE, warning=FALSE}
knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/outliers/boxplot_OverallCond.png")


```

-   Valores entre 1 y 9.

-   Pico muy marcado en 5.

-   Caja centrada en 5-6.

-   Pocos casos en extremos (1, 9).

```{r YearBuilt, echo=FALSE, warning=FALSE}
knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/varsnum/distribucion_YearBuilt.png")



```

```{r YearBuilt2, echo=FALSE, warning=FALSE}
knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/outliers/boxplot_YearBuilt.png")



```

-   Rango amplio (1870–2010).

-   Incremento progresivo hasta 2000.

-   Concentración alta en décadas recientes.

-   Boxplot concentrado en 1950–2000.

```{r YearRemodAdd, echo=FALSE, warning=FALSE}

knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/varsnum/distribucion_YearRemodAdd.png")


```

```{r YearRemodAdd2, echo=FALSE, warning=FALSE}

knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/outliers/boxplot_YearRemodAdd.png")


```

-   Rango 1950–2010.

-   Mayor actividad de remodelación cerca de 1990 y 2010, 1950 presenta remodelaciones altas.

-   Boxplot abarca 1960–2000.

-   Pocos valores anteriores a 1960.

#### Variables Numéricas Relacionadas con Áreas y Calidad

```{r LotFrontage, echo=FALSE, warning=FALSE}

knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/varsnum/distribucion_LotFrontage.png")

```

```{r LotFrontage2, echo=FALSE, warning=FALSE}

knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/outliers/boxplot_LotFrontage.png")

```

-   Pico cercano a 60-70.

-   Muchos valores faltantes.

-   Cola derecha larga, outliers por encima de 150.

```{r MasVnrArea, echo=FALSE, warning=FALSE}
knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/varsnum/distribucion_MasVnrArea.png")


```

```{r MasVnrArea2, echo=FALSE, warning=FALSE}
knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/outliers/boxplot_MasVnrArea.png")


```

-   Mayoría en 0 (sin acabado de mampostería).

-   Fuerte sesgo a la derecha.

-   Outliers hasta 1600.

#### Variables Numéricas Relacionadas con el Garaje

```{r GarageArea, echo=FALSE, warning=FALSE}

knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/varsnum/distribucion_GarageArea.png")


```

```{r GarageArea2, echo=FALSE, warning=FALSE}

knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/outliers/boxplot_GarageArea.png")


```

-   Mayoría entre 400–600.

-   Distribución sesgada a la derecha.

-   Outliers por encima de 1000.

```{r GarageCars, echo=FALSE, warning=FALSE}
# GarageCars: Capacidad de autos en el garaje
knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/varsnum/distribucion_GarageCars.png")

```

```{r GarageCars2, echo=FALSE, warning=FALSE}
# GarageCars: Capacidad de autos en el garaje
knitr::include_graphics("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/figures/outliers/boxplot_GarageCars.png")

```

-   Pico en 2 autos.

-   Rango 0–4.

-   Pocos outliers en 4.

Las variables numéricas, como áreas y precios, se distribuyen con asimetría a la derecha y tienen outliers significativos. Las variables de calidad se concentran en rangos medios y se detectan datos faltantes en algunas. Esto indica que será necesario aplicar transformaciones , tratar outliers y profundizar en el análisis de las variables categóricas para extraer patrones relevantes en la valoración de propiedades

## Identificación de faltantes y outliers

```{r missing-info, echo=FALSE, warning=FALSE, results='asis'}
# Variables de interés
vars_missing <- c("LotFrontage", "Alley", "PoolQC", "Fence", "MiscFeature")

# Crear la tabla con formato en la columna UniqueValues
missing_info <- lapply(vars_missing, function(var) {
  missing_count <- sum(is.na(datos[[var]]))
  missing_percent <- (missing_count / nrow(datos)) * 100
  unique_vals <- unique(datos[[var]])
  # Convertir a cadena y aplicar salto de línea cada 50 caracteres
  unique_vals_str <- paste(unique_vals, collapse = ", ")
  unique_vals_str <- paste(strwrap(unique_vals_str, width = 50), collapse = "\n")
  data.frame(
    Variable = var,
    MissingCount = missing_count,
    MissingPercent = round(missing_percent, 2),
    UniqueValues = unique_vals_str,
    stringsAsFactors = FALSE
  )
})
missing_info_df <- do.call(rbind, missing_info)

# Mostrar la tabla con kable y kableExtra
library(knitr)
library(kableExtra)
kable(missing_info_df, 
      caption = "Resumen de Valores Faltantes en Variables Seleccionadas", 
      row.names = FALSE) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)

```

## Análisis de Outliers

```{r outliers1, echo=FALSE, warning=FALSE}

vars_outlier <- c("SalePrice", "GrLivArea", "LotArea", "X1stFlrSF", "TotalBsmtSF", "MasVnrArea", "GarageArea")

outlier_summary <- lapply(vars_outlier, function(var) {
  s <- summary(datos[[var]])
  quantiles <- quantile(datos[[var]], 
                        probs = c(0.01, 0.05, 0.25, 0.50, 0.75, 0.95, 0.99), 
                        na.rm = TRUE)
  data.frame(
    Variable = var,
    Min = as.numeric(s["Min."]),
    `1%` = round(as.numeric(quantiles["1%"]), 2),
    `5%` = round(as.numeric(quantiles["5%"]), 2),
    `25%` = round(as.numeric(quantiles["25%"]), 2),
    Median = as.numeric(s["Median"]),
    `75%` = round(as.numeric(quantiles["75%"]), 2),
    `95%` = round(as.numeric(quantiles["95%"]), 2),
    `99%` = round(as.numeric(quantiles["99%"]), 2),
    Max = as.numeric(s["Max."]),
    stringsAsFactors = FALSE
  )
})
outlier_summary_df <- do.call(rbind, outlier_summary)
library(knitr)
kable(outlier_summary_df, caption = "Resumen Estadístico y Cuantiles para Análisis de Outliers", row.names = FALSE)


```

## Pruebas de Normalidad

```{r normality, echo=FALSE, warning=FALSE}


run_normality_tests <- function(x) {
  x <- na.omit(x)  # Eliminar valores faltantes
  if (length(x) < 3) {
    return(data.frame(Test = NA, Statistic = NA, P.value = NA))
  }
  # Shapiro-Wilk
  sw <- shapiro.test(x)
  # Anderson-Darling
  ad <- ad.test(x)
  # Kolmogorov-Smirnov (comparado con la normal parametrizada)
  ks <- ks.test(x, "pnorm", mean = mean(x), sd = sd(x))
  # Lilliefors
  li <- lillie.test(x)
  
  # Crear data frame con los resultados
  results_df <- data.frame(
    Test = c("Shapiro-Wilk", "Anderson-Darling", "Kolmogorov-Smirnov", "Lilliefors"),
    Statistic = c(as.numeric(sw$statistic), as.numeric(ad$statistic),
                  as.numeric(ks$statistic), as.numeric(li$statistic)),
    P.value = c(sw$p.value, ad$p.value, ks$p.value, li$p.value)
  )
  return(results_df)
}



```

Se definen grupos de variables como la variable objetivo y las variables numéricas de área, calidad y años, para evaluar su normalidad mediante pruebas estadísticas. Los resultados de las pruebas de normalidad se presentan a continuación:

### Grupo 1: Variable objetivo y áreas

```{r normality2, echo=FALSE, warning=FALSE}


vars_group1 <- c("SalePrice", "GrLivArea", "LotArea", "X1stFlrSF", "TotalBsmtSF")

# Iterar por cada variable y mostrar la tabla de resultados
for (var in vars_group1) {
  test_results <- run_normality_tests(datos[[var]])
  # Agregar el nombre de la variable al data frame
  test_results <- cbind(Variable = var, test_results)
  
  # Mostrar la tabla con kable
  print(kable(test_results, digits = 4, caption = paste("Pruebas de Normalidad para", var)))
}



```

### Grupo 2: Variables de calidad y construcción

```{r normality3, echo=FALSE, warning=FALSE}

vars_group2 <- c("OverallQual", "OverallCond", "YearBuilt", "YearRemodAdd")

for (var in vars_group2) {
  test_results <- run_normality_tests(datos[[var]])
  test_results <- cbind(Variable = var, test_results)
  print(kable(test_results, digits = 4, caption = paste("Pruebas de Normalidad para", var)))
}



```

### Grupo 3: Variables relacionadas con acabados y garaje

```{r normality4, echo=FALSE, warning=FALSE}

vars_group3 <- c("MasVnrArea", "GarageArea")

for (var in vars_group3) {
  test_results <- run_normality_tests(datos[[var]])
  test_results <- cbind(Variable = var, test_results)
  print(kable(test_results, digits = 4, caption = paste("Pruebas de Normalidad para", var)))
}



```

Las pruebas de normalidad en todos los grupos de variables arrojan p-valores extremadamente bajos (p \< 2.2e-16 en la mayoría de los casos), lo que indica que ninguna de estas variables sigue una distribución normal según los test de Shapiro-Wilk, Anderson-Darling, Kolmogorov-Smirnov y Lilliefors. Esto es especialmente notable en variables como SalePrice, LotArea y MasVnrArea, que presentan un marcado sesgo a la derecha y outliers. Aunque algunas variables tienen valores de W relativamente altos, el tamaño de la muestra (n=1460) hace que incluso desviaciones leves se vuelvan estadísticamente significativas. En conclusión, la evidencia sugiere que es necesario aplicar transformaciones y/o estrategias de manejo de outliers para aproximar la normalidad y estabilizar la varianza antes de proceder con el modelado predictivo.

## Preguntas Exploratorias

A partir de esta exploración inicial, se identificaron patrones y características clave en las variables categóricas y numéricas. Estos insights serán fundamentales para la limpieza, transformación y modelado de los datos, permitiendo construir modelos predictivos precisos y robustos.

Adicionalmente,surgen interrogantes sobre la relación entre las variables y su impacto en el precio de venta, por lo que previo a las transformaciones las cuales se responden de manera iterativa en el análisis exploratorio de datos. A continuación, se presentan las preguntas de investigación que guiarán el análisis y modelado de los datos:

1.  **¿Cómo se relacionan las variables de área (GrLivArea, LotArea, X1stFlrSF, TotalBsmtSF) con el precio de venta y cómo varían estas relaciones según categorías de calidad (OverallQual, OverallCond) y ubicación (Neighborhood, MSZoning)?**

```{r q1, echo=FALSE, warning=FALSE}
library(ggplot2)
library(dplyr)
library(gridExtra)

# Cargar datos y ajustar variables
datos$OverallQual  <- as.factor(datos$OverallQual)
datos$OverallCond  <- as.factor(datos$OverallCond)
datos$Neighborhood <- as.factor(datos$Neighborhood)
datos$MSZoning     <- as.factor(datos$MSZoning)

# Gráficos:

p1 <- ggplot(datos, aes(x = GrLivArea, y = SalePrice, color = OverallQual)) +
  geom_point(alpha = 0.6) +
  labs(title = "GrLivArea vs SalePrice\npor OverallQual",
       x = "GrLivArea", y = "SalePrice") +
  theme_minimal()

p2 <- ggplot(datos, aes(x = LotArea, y = SalePrice, color = OverallCond)) +
  geom_point(alpha = 0.6) +
  labs(title = "LotArea vs SalePrice\npor OverallCond",
       x = "LotArea", y = "SalePrice") +
  theme_minimal()

p3 <- ggplot(datos, aes(x = X1stFlrSF, y = SalePrice)) +
  geom_point(alpha = 0.6, color = "darkgreen") +
  facet_wrap(~ Neighborhood) +
  labs(title = "X1stFlrSF vs SalePrice\npor Neighborhood",
       x = "X1stFlrSF", y = "SalePrice") +
  theme_minimal()

p4 <- ggplot(datos, aes(x = TotalBsmtSF, y = SalePrice)) +
  geom_point(alpha = 0.6, color = "purple") +
  facet_wrap(~ MSZoning) +
  labs(title = "TotalBsmtSF vs SalePrice\npor MSZoning",
       x = "TotalBsmtSF", y = "SalePrice") +
  theme_minimal()

# Presentación elegante: organizar en una cuadrícula
grid.arrange(p1, p2, p3, p4, ncol = 2)



```

-   **GrLivArea vs SalePrice**\
    En el diagrama de dispersión se aprecia una **tendencia claramente positiva**: a mayor superficie habitable (GrLivArea), mayor tiende a ser el precio de venta.

    -   Se observa que los puntos con OverallQual más alto se concentran en la parte superior de la nube de puntos, indicando que casas con más área y mejor calidad se venden a precios notablemente superiores.

-   **LotArea vs SalePrice**\
    Existe también una relación positiva, pero es más dispersa que GrLivArea. Se ven valores muy altos de LotArea que no siempre conllevan precios igual de altos, lo cual sugiere que el tamaño del lote por sí solo no determina el precio de forma tan directa como el área habitable.

    -   Al superponer la variable OverallCond , se aprecia que las viviendas con mejor condición se ubican en rangos de precio más elevados, aun con lotes de tamaño similar.

<!-- -->

-   **X1stFlrSF vs SalePrice (por Neighborhood)**\
    En la gráfica se percibe nuevamente una relación creciente entre la superficie del primer piso y el precio.

    -   Sin embargo, Neighborhood introduce diferencias: barrios de mayor nivel muestran precios más altos incluso para valores de X1stFlrSF relativamente moderados, mientras que en barrios de menor nivel se requieren superficies mucho mayores para alcanzar precios similares.

-   **TotalBsmtSF vs SalePrice (por MSZoning)**\
    De igual modo, se ve correlación positiva entre el tamaño del sótano y el precio.

    -   La zonificación segmenta el mercado: en zonas residenciales de baja densidad los precios suelen ser más elevados que en zonas multifamiliares, a igualdad de TotalBsmtSF.

Las áreas de la vivienda guardan una relación positiva con SalePrice. Esa relación se modula por la calidad/condición de la vivienda y por la ubicación .

2.  **¿Qué impacto tienen los años de construcción y remodelación (YearBuilt, YearRemodAdd) en el precio? ¿Existen tendencias o agrupaciones de propiedades antiguas versus modernas que influyan en SalePrice?**

```{r q2, echo=FALSE, warning=FALSE}
library(ggplot2)
library(dplyr)
library(gridExtra)

# Cargar el dataset y crear la variable DecadeBuilt
if("YearBuilt" %in% names(datos)){
  datos <- datos %>% mutate(DecadeBuilt = floor(YearBuilt / 10) * 10)
} else {
  stop("La variable 'YearBuilt' no se encuentra en el dataset.")
}

# Gráfico 1: YearBuilt vs SalePrice con línea de tendencia
p1 <- ggplot(datos, aes(x = YearBuilt, y = SalePrice)) +
  geom_point(alpha = 0.6, color = "steelblue") +
  geom_smooth(method = "lm", se = FALSE, color = "darkred") +
  labs(title = "YearBuilt vs SalePrice",
       x = "Build Year",
       y = "Sale Price") +
  theme_minimal()

# Gráfico 2: Boxplot de SalePrice por Década de Construcción
p2 <- ggplot(datos, aes(x = factor(DecadeBuilt), y = SalePrice)) +
  geom_boxplot(fill = "lightgreen") +
  labs(title = " SalePrice per build decade",
       x = "Build decade",
       y = "Sale Price") +
  theme_minimal()

# Gráfico 3: YearRemodAdd vs SalePrice con línea de tendencia
p3 <- ggplot(datos, aes(x = YearRemodAdd, y = SalePrice)) +
  geom_point(alpha = 0.6, color = "purple") +
  geom_smooth(method = "lm", se = FALSE, color = "darkorange") +
  labs(title = "YearRemodAdd vs SalePrice",
       x = "Remodeling year",
       y = "Sale Price") +
  theme_minimal()

# Organizar los gráficos en una cuadrícula
grid.arrange(p1, p2, p3, ncol = 2)




```

-   **YearBuilt vs SalePrice**\
    El gráfico de dispersión con una línea de tendencia sugiere que **las casas más nuevas** suelen tener precios promedio más altos.

    -   Sin embargo, hay puntos antiguos (antes de 1940) con precios elevados, lo cual indica que algunas casas históricas o muy bien conservadas también pueden alcanzar precios altos, probablemente por estar en barrios deseados o haber sido remodeladas.

-   **SalePrice por década de construcción**\
    En la gráfica de cajas (boxplot) por década, se ve un incremento gradual en el precio mediano con cada década más reciente, aunque hay traslapes entre décadas y algunos outliers altos en décadas anteriores.

-   **YearRemodAdd vs SalePrice**\
    El diagrama de dispersión muestra una tendencia similar: las casas con remodelaciones más recientes suelen presentar precios mayores. Se evidencia que la remodelación eleva el valor de propiedades antiguas.

Las viviendas construidas o renovadas más recientemente tienden a tener precios mayores, aunque propiedades muy antiguas y con alto mantenimiento pueden equipararse a precios de casas más nuevas.

3.  **¿Cuáles son las diferencias en la distribución de precios entre los distintos tipos de construcción y estilos de vivienda (BldgType, HouseStyle), y qué patrones se observan en función de la estructura física de la propiedad?**

```{r q3, echo=FALSE, warning=FALSE}

# Cargar el dataset y ajustar variables
datos$BldgType   <- as.factor(datos$BldgType)
datos$HouseStyle <- as.factor(datos$HouseStyle)

# Gráfico 1: Boxplot de SalePrice por BldgType
p1 <- ggplot(datos, aes(x = BldgType, y = SalePrice)) +
  geom_boxplot(fill = "lightblue") +
  labs(title = "SalePrice by BldgType",
       x = "Building Type",
       y = "SalePrice") +
  theme_minimal()

# Gráfico 2: Boxplot de SalePrice por HouseStyle
p2 <- ggplot(datos, aes(x = HouseStyle, y = SalePrice)) +
  geom_boxplot(fill = "lightgreen") +
  labs(title = "SalePrice by HouseStyle",
       x = "House Style",
       y = "SalePrice") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Gráfico 3: Faceted Boxplots por BldgType y HouseStyle
p3 <- ggplot(datos, aes(x = "", y = SalePrice)) +
  geom_boxplot(fill = "coral") +
  facet_grid(BldgType ~ HouseStyle) +
  labs(title = "SalePrice by BldgType and HouseStyle",
       x = "",
       y = "SalePrice") +
  theme_minimal() +
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())

# Organizar y mostrar los gráficos en una cuadrícula
grid.arrange(p1, p2, p3, ncol = 1)



```

-   **SalePrice por BldgType**\
    El boxplot muestra que 1Fam suele tener la mediana de precios más alta. Otras tipologías presentan mediana y dispersión de precios algo menores.

-   **SalePrice por HouseStyle**\
    Se ven estilos como 1Story, 1.5Fin, 2Story, etc.

    -   Generalmente, 2Story presenta una mediana algo más elevada que 1Story. Estilos con 1.5 pisos tienen una mediana menor, aunque con bastante dispersión.

-   **SalePrice por BldgType y HouseStyle (combinados)**\
    Se confirma que las unifamiliares de 2 pisos tienden a precios más altos. Los demás estilos y tipos presentan menor valor medio, aunque con outliers en todos los grupos.

4.  **¿De qué manera afectan los acabados exteriores y materiales (Exterior1st, Exterior2nd, MasVnrType, MasVnrArea) la valoración de las viviendas? ¿Se observa que ciertos materiales o condiciones exteriores se asocian a precios más altos o más bajos?**

```{r q4, echo=FALSE, warning=FALSE}


# Cargar el dataset y ajustar variables
datos$Exterior1st <- as.factor(datos$Exterior1st)
datos$Exterior2nd <- as.factor(datos$Exterior2nd)
datos$MasVnrType  <- as.factor(datos$MasVnrType)

# Gráfico 1: Boxplot de SalePrice by Exterior1st
p1 <- ggplot(datos, aes(x = Exterior1st, y = SalePrice)) +
  geom_boxplot(fill = "lightblue") +
  labs(title = "SalePrice by Exterior1st", x = "Exterior1st", y = "SalePrice") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Gráfico 2: Boxplot de SalePrice by Exterior2nd
p2 <- ggplot(datos, aes(x = Exterior2nd, y = SalePrice)) +
  geom_boxplot(fill = "lightgreen") +
  labs(title = "SalePrice by Exterior2nd", x = "Exterior2nd", y = "SalePrice") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Gráfico 3: Boxplot de SalePrice by MasVnrType
p3 <- ggplot(datos, aes(x = MasVnrType, y = SalePrice)) +
  geom_boxplot(fill = "lightcoral") +
  labs(title = "SalePrice by MasVnrType", x = "MasVnrType", y = "SalePrice") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Gráfico 4: Scatter plot de MasVnrArea vs SalePrice con línea de tendencia
p4 <- ggplot(datos, aes(x = MasVnrArea, y = SalePrice)) +
  geom_point(alpha = 0.6, color = "purple") +
  geom_smooth(method = "lm", se = FALSE, color = "darkred") +
  labs(title = "MasVnrArea vs SalePrice", x = "MasVnrArea", y = "SalePrice") +
  theme_minimal()

# Organizar y mostrar los gráficos en una cuadrícula
grid.arrange(p1, p2, p3, p4, ncol = 2)



```

-   **SalePrice por Exterior1st y Exterior2nd**\
    Los boxplots muestran diferencias entre materiales: algunos como “Stone” o “Brick” tienen medianas de precio más altas. Acabados más económicos tienden a mediana inferior.

-   **SalePrice por MasVnrType**\
    Se ven categorías como “BrkFace”, “Stone”, “None”. “Stone” y “BrkFace” suelen asociarse a valores más altos que “None”.

-   **MasVnrArea vs SalePrice**\
    El diagrama de dispersión y la línea de tendencia reflejan una correlación positiva: cuanto mayor es el área de recubrimiento en mampostería (ladrillo, piedra, etc.), mayor suele ser el precio de venta.

\
Los acabados exteriores y la presencia de mampostería se asocian con precios más altos, indicando que la calidad y estética exterior añade valor.

5.  **¿Cómo influyen las condiciones y características del sótano (BsmtQual, BsmtCond, BsmtFinType1, BsmtFinSF1, BsmtFinSF2) en el precio?¿Existe un efecto diferencial entre casas con sótanos terminados y sin terminar?**

```{r q5, echo=FALSE, warning=FALSE}


datos$BsmtQual <- as.factor(datos$BsmtQual)
datos$BsmtCond <- as.factor(datos$BsmtCond)
datos$BsmtFinType1 <- as.factor(datos$BsmtFinType1)

# Crear la variable BasementStatus para identificar sótanos terminados vs. sin terminar
datos$BasementStatus <- ifelse(is.na(datos$BsmtFinType1) | datos$BsmtFinType1 == "Unf", 
                               "Unfinished", "Finished")
datos$BasementStatus <- as.factor(datos$BasementStatus)

# Gráfico 1: Boxplot de SalePrice vs BsmtQual
p1 <- ggplot(datos, aes(x = BsmtQual, y = SalePrice)) +
  geom_boxplot(fill = "lightblue") +
  labs(title = "SalePrice vs BsmtQual", x = "Basement Quality", y = "SalePrice") +
  theme_minimal()

# Gráfico 2: Boxplot de SalePrice vs BsmtCond
p2 <- ggplot(datos, aes(x = BsmtCond, y = SalePrice)) +
  geom_boxplot(fill = "lightgreen") +
  labs(title = "SalePrice vs BsmtCond", x = "Basement Condition", y = "SalePrice") +
  theme_minimal()

# Gráfico 3: Boxplot de SalePrice vs BsmtFinType1
p3 <- ggplot(datos, aes(x = BsmtFinType1, y = SalePrice)) +
  geom_boxplot(fill = "lightcoral") +
  labs(title = "SalePrice vs BsmtFinType1", x = "Finished Basement Type", y = "SalePrice") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Gráfico 4: Scatter plot de BsmtFinSF1 vs SalePrice
p4 <- ggplot(datos, aes(x = BsmtFinSF1, y = SalePrice)) +
  geom_point(alpha = 0.6, color = "purple") +
  geom_smooth(method = "lm", se = FALSE, color = "darkred") +
  labs(title = "BsmtFinSF1 vs SalePrice", x = "Basement Finished Area 1", y = "SalePrice") +
  theme_minimal()

# Gráfico 5: Scatter plot de BsmtFinSF2 vs SalePrice
p5 <- ggplot(datos, aes(x = BsmtFinSF2, y = SalePrice)) +
  geom_point(alpha = 0.6, color = "orange") +
  geom_smooth(method = "lm", se = FALSE, color = "darkblue") +
  labs(title = "BsmtFinSF2 vs SalePrice", x = "Basement Finished Area 2", y = "SalePrice") +
  theme_minimal()

# Gráfico 6: Boxplot de SalePrice por BasementStatus
p6 <- ggplot(datos, aes(x = BasementStatus, y = SalePrice)) +
  geom_boxplot(fill = "wheat") +
  labs(title = "SalePrice by Basement Finished Status", x = "Basement Status", y = "SalePrice") +
  theme_minimal()

# Organizar y mostrar los gráficos en una cuadrícula de 3 columnas
grid.arrange(p1, p2, p3, p4, p5, p6, ncol = 3)



```

-   **SalePrice vs BsmtQual, BsmtCond, BsmtFinType**\
    Los boxplots muestran que calidades altas (Ex, Gd) y condiciones buenas se asocian con precios medianos superiores. BsmtFinType (GLQ, ALQ) —acabados de mayor nivel— también suben el precio respecto a un sótano sin terminar (Unf).

-   **BsmtFinSF1 y BsmtFinSF2 vs SalePrice**\
    Los diagramas de dispersión evidencian una relación positiva: a más metros cuadrados terminados en el sótano, mayor precio.

    -   BsmtFinSF1 suele tener un impacto más claro que BsmtFinSF2, probablemente porque es el área de acabado principal.

\
Un sótano bien calificado y con superficies terminadas aumenta el espacio habitable y, por ende, el valor de la vivienda.

6.  **¿Qué rol juegan las variables relacionadas con el garaje (GarageType, GarageArea, GarageCars, GarageQual, GarageCond) en la determinación del precio de venta? ¿Están las propiedades con garajes de mejor calidad o mayor capacidad asociadas a precios superiores?**

```{r q6, echo=FALSE, warning=FALSE}
# Cargar el dataset y convertir variables categóricas a factor
datos$GarageType <- as.factor(datos$GarageType)
datos$GarageQual <- as.factor(datos$GarageQual)
datos$GarageCond <- as.factor(datos$GarageCond)

# Gráfico 1: Boxplot de SalePrice vs GarageType
p1 <- ggplot(datos, aes(x = GarageType, y = SalePrice)) +
  geom_boxplot(fill = "lightblue") +
  labs(title = "SalePrice by GarageType", x = "Garage Type", y = "SalePrice") +
  theme_minimal()

# Gráfico 2: Scatter plot de GarageArea vs SalePrice con línea de tendencia
p2 <- ggplot(datos, aes(x = GarageArea, y = SalePrice)) +
  geom_point(alpha = 0.6, color = "darkgreen") +
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  labs(title = "GarageArea vs SalePrice", x = "Garage Area", y = "SalePrice") +
  theme_minimal()

# Gráfico 3: Scatter plot de GarageCars vs SalePrice con línea de tendencia
p3 <- ggplot(datos, aes(x = GarageCars, y = SalePrice)) +
  geom_point(alpha = 0.6, color = "blue") +
  geom_smooth(method = "lm", se = FALSE, color = "darkorange") +
  labs(title = "GarageCars vs SalePrice", x = "Number of Cars", y = "SalePrice") +
  theme_minimal()

# Gráfico 4: Boxplot de SalePrice vs GarageQual
p4 <- ggplot(datos, aes(x = GarageQual, y = SalePrice)) +
  geom_boxplot(fill = "lightcoral") +
  labs(title = "SalePrice by GarageQual", x = "Garage Quality", y = "SalePrice") +
  theme_minimal()

# Gráfico 5: Boxplot de SalePrice vs GarageCond
p5 <- ggplot(datos, aes(x = GarageCond, y = SalePrice)) +
  geom_boxplot(fill = "lightyellow") +
  labs(title = "SalePrice by GarageCond", x = "Garage Condition", y = "SalePrice") +
  theme_minimal()

# Organizar y mostrar los gráficos en una cuadrícula
grid.arrange(p1, p2, p3, p4, p5, ncol = 2)



```

-   **SalePrice por GarageType**\
    Viviendas con garajes “Attached” o “BuiltIn” suelen tener precios medianos mayores que aquellas con “CarPort” o “NA” .

-   **GarageArea vs SalePrice**\
    Se ve una **correlación positiva**: un garaje más grande tiende a asociarse con precios más altos.

-   **GarageCars vs SalePrice**\
    La línea que conecta la media según el número de coches sube de forma notable: garajes de 2-3 plazas suelen estar en rangos de precio más elevados que los de 1 plaza.

-   **SalePrice por GarageQual y GarageCond**\
    Garajes con calidades superiores (Ex, Gd) presentan precios medianos notablemente más altos. Condiciones regulares (TA) o pobres (Po) reducen la mediana.

    \
    Un garaje amplio, con capacidad suficiente y buena calidad incrementa el valor de la vivienda, confirmando su importancia en la percepción del comprador.

-   **¿Existen patrones de desequilibrio o baja representatividad en ciertas variables categóricas (por ejemplo, Alley, PoolQC, MiscFeature) que requieran agrupar categorías o realizar recodificaciones para un análisis más fiable?**

```{r q7, echo=FALSE, warning=FALSE}

datos$Alley       <- as.factor(datos$Alley)
datos$PoolQC      <- as.factor(datos$PoolQC)
datos$MiscFeature <- as.factor(datos$MiscFeature)

# Calcular las tablas de frecuencia y convertirlas a data frames
df_alley <- as.data.frame(table(datos$Alley, useNA = "ifany"))
names(df_alley) <- c("Alley", "Count")

df_poolqc <- as.data.frame(table(datos$PoolQC, useNA = "ifany"))
names(df_poolqc) <- c("PoolQC", "Count")

df_misc <- as.data.frame(table(datos$MiscFeature, useNA = "ifany"))
names(df_misc) <- c("MiscFeature", "Count")

# Mostrar las tablas de frecuencia de forma elegante
kable(df_alley, caption = "Frequency of Alley", align = "c") %>%
  kable_styling(full_width = FALSE, position = "center")

kable(df_poolqc, caption = "Frequency of PoolQC", align = "c") %>%
  kable_styling(full_width = FALSE, position = "center")

kable(df_misc, caption = "Frequency of MiscFeature", align = "c") %>%
  kable_styling(full_width = FALSE, position = "center")


```

```{r q7b, echo=FALSE, warning=FALSE}
# Crear gráficos de barras

# Gráfico para Alley
p1 <- ggplot(datos, aes(x = Alley)) +
  geom_bar(fill = "steelblue") +
  labs(title = "Frequency of Alley", x = "Alley", y = "Count") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Gráfico para PoolQC
p2 <- ggplot(datos, aes(x = PoolQC)) +
  geom_bar(fill = "salmon") +
  labs(title = "Frequency of PoolQC", x = "PoolQC", y = "Count") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Gráfico para MiscFeature
p3 <- ggplot(datos, aes(x = MiscFeature)) +
  geom_bar(fill = "darkseagreen") +
  labs(title = "Frequency of MiscFeature", x = "MiscFeature", y = "Count") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Organizar y mostrar los gráficos en una cuadrícula
grid.arrange(p1, p2, p3, ncol = 1)




```

-   **Frecuencia de Alley**\
    El gráfico de barras muestra que la mayoría de los registros están en “NA” , y muy pocos tienen “Grvl” o “Pave”. Esto indica fuerte desequilibrio.

-   **Frecuencia de PoolQC**\
    La gran mayoría también aparece como “NA”, y solo un puñado de viviendas tiene calificaciones de piscina (Ex, Gd, etc.). Claramente hay pocas casas con piscina.

-   **Frecuencia de MiscFeature**\
    De nuevo, “NA” es dominante. Las categorías como “Shed”, “Tenc”, etc. son muy minoritarias.

\
Estas variables tienen muchos valores nulos o categorías con muy pocas observaciones, por lo que, para un análisis o modelado predictivo, probablemente se necesite agrupar, recodificar o descartar en ciertos casos.

8.  **¿Cómo se comportan las variables relacionadas con la ubicación y configuración del terreno (LotShape, LandContour, Street, Utilities) y qué relación tienen con el precio de venta?**

```{r q8, echo=FALSE, warning=FALSE}

datos$LotShape    <- as.factor(datos$LotShape)
datos$LandContour <- as.factor(datos$LandContour)
datos$Street      <- as.factor(datos$Street)
datos$Utilities   <- as.factor(datos$Utilities)

# Crear data frames con las tablas de frecuencia
df_lotshape <- as.data.frame(table(datos$LotShape, useNA = "ifany"))
names(df_lotshape) <- c("LotShape", "Count")

df_landcontour <- as.data.frame(table(datos$LandContour, useNA = "ifany"))
names(df_landcontour) <- c("LandContour", "Count")

df_street <- as.data.frame(table(datos$Street, useNA = "ifany"))
names(df_street) <- c("Street", "Count")

df_utilities <- as.data.frame(table(datos$Utilities, useNA = "ifany"))
names(df_utilities) <- c("Utilities", "Count")

# Mostrar las tablas de frecuencia de forma elegante con kable
kable(df_lotshape, caption = "Frequency of LotShape", align = "c") %>%
  kable_styling(full_width = FALSE, position = "center")
kable(df_landcontour, caption = "Frequency of LandContour", align = "c") %>%
  kable_styling(full_width = FALSE, position = "center")
kable(df_street, caption = "Frequency of Street", align = "c") %>%
  kable_styling(full_width = FALSE, position = "center")
kable(df_utilities, caption = "Frequency of Utilities", align = "c") %>%
  kable_styling(full_width = FALSE, position = "center")



```

```{r q8b, echo=FALSE, warning=FALSE}
# Crear gráficos de boxplots

# Gráfico 1: SalePrice vs LotShape
p1 <- ggplot(datos, aes(x = LotShape, y = SalePrice)) +
  geom_boxplot(fill = "lightblue") +
  labs(title = "SalePrice by LotShape", x = "Lot Shape", y = "SalePrice") +
  theme_minimal()

# Gráfico 2: SalePrice vs LandContour
p2 <- ggplot(datos, aes(x = LandContour, y = SalePrice)) +
  geom_boxplot(fill = "lightgreen") +
  labs(title = "SalePrice by LandContour", x = "Land Contour", y = "SalePrice") +
  theme_minimal()

# Gráfico 3: SalePrice vs Street
p3 <- ggplot(datos, aes(x = Street, y = SalePrice)) +
  geom_boxplot(fill = "lightcoral") +
  labs(title = "SalePrice by Street", x = "Street Type", y = "SalePrice") +
  theme_minimal()

# Gráfico 4: SalePrice vs Utilities
p4 <- ggplot(datos, aes(x = Utilities, y = SalePrice)) +
  geom_boxplot(fill = "wheat") +
  labs(title = "SalePrice by Utilities", x = "Utilities", y = "SalePrice") +
  theme_minimal()

# Organizar y mostrar los gráficos en una cuadrícula
grid.arrange(p1, p2, p3, p4, ncol = 2)


```

-   **SalePrice por LotShape**\
    Los boxplots muestran que lotes de forma regular (Reg) tienden a un precio mediano más alto, mientras que lotes muy irregulares (IR3) suelen tener precios más bajos.

-   **SalePrice por LandContour**\
    Los terrenos “Lvl” (nivelados) muestran, en general, medianas más altas que “Bnk” o “HLS” (terrenos con pendientes). No obstante, se observan outliers en todos los grupos.

-   **SalePrice por Street**\
    Calles pavimentadas (Pave) se asocian a precios más elevados que calles de grava (Grvl). La diferencia no es tan marcada como en otras variables, pero sí visible.

-   **SalePrice por Utilities**\
    Tener todos los servicios públicos (AllPub) presenta una mediana superior frente a “NoSeWa”. La mayoría de propiedades se concentran en “AllPub”, con pocas en la otra categoría.

\
Aunque no tan determinantes como el área o la calidad de construcción, estas variables de configuración y servicios del terreno influyen en la valoración final, especialmente cuando se combinan con la ubicación .

9.  **¿Qué variables muestran mayor presencia de outliers o sesgo en su distribución, y cuál es el impacto de estos extremos en los modelos predictivos? ¿Es necesario aplicar transformaciones (como logaritmos) o segmentaciones específicas?**

```{r q9, echo=FALSE, warning=FALSE}


if (!require(moments)) {
  install.packages("moments")
  library(moments)
} else {
  library(moments)
}
# Variables a evaluar
vars <- c("SalePrice", "GrLivArea", "LotArea", "TotalBsmtSF", "GarageArea", "MasVnrArea")

# Calcular skewness para cada variable y redondear
skew_values <- sapply(vars, function(v) { skewness(na.omit(datos[[v]])) })
skew_table <- data.frame(Variable = vars, Skewness = round(skew_values, 2))

# Mostrar la tabla de skewness con kable
kable(skew_table, caption = "Skewness of Selected Variables", align = "c") %>%
  kable_styling(full_width = FALSE, position = "center")


```

```{r q9b, echo=FALSE, warning=FALSE}

# Función para crear histogramas y boxplots
create_plots <- function(var) {
  p_hist <- ggplot(datos, aes_string(x = var)) +
    geom_histogram(fill = "skyblue", bins = 30, color = "black") +
    labs(title = paste("Histogram of", var),
         x = var, y = "Frequency") +
    theme_minimal()
  
  p_box <- ggplot(datos, aes_string(y = var)) +
    geom_boxplot(fill = "orange", outlier.colour = "red", outlier.shape = 16) +
    labs(title = paste("Boxplot of", var),
         y = var) +
    theme_minimal()
  
  list(p_hist = p_hist, p_box = p_box)
}

# Generar plots para cada variable
plot_list <- lapply(vars, create_plots)

# Ejemplo: Organizar los gráficos de las dos primeras variables (SalePrice y GrLivArea)
grid.arrange(plot_list[[1]]$p_hist, plot_list[[1]]$p_box,
             plot_list[[2]]$p_hist, plot_list[[2]]$p_box,
             ncol = 2)

# Opcional: Crear y mostrar histogramas log-transformados para variables con valores positivos
create_log_plot <- function(var) {
  data_nonzero <- datos %>% filter(.[[var]] > 0)
  p_log <- ggplot(data_nonzero, aes_string(x = paste0("log(", var, ")"))) +
    geom_histogram(fill = "lightgreen", bins = 30, color = "black") +
    labs(title = paste("Histogram of log(", var, ")", sep=""),
         x = paste("log(", var, ")", sep=""), y = "Frequency") +
    theme_minimal()
  p_log
}

# Generar histogramas log-transformados para todas las variables y organizarlos en una cuadrícula
log_plots <- lapply(vars, create_log_plot)
do.call(grid.arrange, c(log_plots, ncol = 2))



```

-   **Histogramas y boxplots de SalePrice y GrLivArea**

    -   **SalePrice**: Presenta una distribución **sesgada a la derecha** (right-skewed) con algunos outliers muy altos.

    -   **GrLivArea**: También muestra outliers en la cola derecha y una distribución asimétrica.\
        Esto sugiere que, para un **modelo de regresión**, podría ser beneficioso aplicar **transformaciones logarítmicas** o alguna técnica de robustez que maneje valores extremos.

SalePrice y GrLivArea tienen outliers y sesgo. Para un análisis predictivo, es habitual considerar log(SalePrice) y, a veces, log(GrLivArea), o bien detectar y tratar outliers que puedan distorsionar la estimación.

10. **¿Cómo se combinan las variables de calidad, área y ubicación para explicar de forma conjunta la variabilidad en el precio de las propiedades?**

```{r q10, echo=FALSE, warning=FALSE}

# Convertir variables categóricas a factor
datos$LotShape    <- as.factor(datos$LotShape)
datos$LandContour <- as.factor(datos$LandContour)
datos$Street      <- as.factor(datos$Street)
datos$Utilities   <- as.factor(datos$Utilities)

# 1. Boxplot: SalePrice vs LotShape
p1 <- ggplot(datos, aes(x = LotShape, y = SalePrice)) +
  geom_boxplot(fill = "lightblue") +
  labs(title = "SalePrice by LotShape",
       x = "Lot Shape", y = "SalePrice") +
  theme_minimal()

# 2. Boxplot: SalePrice vs LandContour
p2 <- ggplot(datos, aes(x = LandContour, y = SalePrice)) +
  geom_boxplot(fill = "lightgreen") +
  labs(title = "SalePrice by LandContour",
       x = "Land Contour", y = "SalePrice") +
  theme_minimal()

# 3. Boxplot: SalePrice vs Street
p3 <- ggplot(datos, aes(x = Street, y = SalePrice)) +
  geom_boxplot(fill = "lightcoral") +
  labs(title = "SalePrice by Street",
       x = "Street Type", y = "SalePrice") +
  theme_minimal()

# 4. Boxplot: SalePrice vs Utilities
p4 <- ggplot(datos, aes(x = Utilities, y = SalePrice)) +
  geom_boxplot(fill = "wheat") +
  labs(title = "SalePrice by Utilities",
       x = "Utilities", y = "SalePrice") +
  theme_minimal()



# Organizar y mostrar los gráficos en una cuadrícula
grid.arrange(p1, p2, p3, p4, ncol = 2)



```

A partir de todos los gráficos:

-   **Calidad (OverallQual, BsmtQual, GarageQual, etc.)**:\
    Las viviendas de mejor calidad y en buen estado destacan con precios altos en todos los ejes (área, sótano, garaje).

-   **Área (GrLivArea, TotalBsmtSF, LotArea)**:\
    El tamaño habitable es uno de los principales impulsores del precio; sin embargo, si la calidad es baja o la ubicación desfavorable, el precio no sube tanto.

-   **Ubicación y servicios (Neighborhood, MSZoning, Street, Utilities)**:\
    Zonas residenciales codiciadas y servicios completos pueden hacer que, incluso con áreas menores, se alcancen precios similares a los de casas grandes en barrios menos deseados.

En conjunto, una casa grande, con acabados de calidad y en un vecindario atractivo, se sitúa en la parte alta del rango de precios. Por el contrario, deficiencias en cualquiera de estas dimensiones pueden limitar el valor final de la vivienda.

### 

## Transformación de Datos y Preprocesamiento

La exploración inicial de los datos perimitió identificar que para una mejor comprensión y modelado de los datos es necesario transformar y preprocesar el conjunto de datos. Dentro de las transformaciones necesarias a realizar se detalllan las siguientes:

-   **Manejo de NAs**:

    -   Reemplazar NAs con “None” en variables categóricas donde la ausencia sea semánticamente “no existe”.

    -   Colocar 0 en variables de área donde no exista sótano/garaje.

    -   Decidir si eliminar variables con demasiados NAs irrelevantes.

-   **Agrupación de categorías poco frecuentes**:

    -   Unir en “Other” o “Rare” para evitar demasiados dummies con muy pocos registros.

-   **Codificación**:

    -   One-Hot para nominales (Neighborhood, BldgType, etc.).

    -   Ordinal para calidades y condiciones (Ex \> Gd \> TA \> Fa \> Po).

-   **Outliers**:

    -   Evaluar la eliminación o recorte (capping) de valores extremadamente altos en variables como SalePrice, GrLivArea, LotArea.

    -   Transformar SalePrice y otras variables con log para reducir skew.

-   **Feature engineering**:

    -   Crear variables de área total, antigüedad, total de baños, puntuaciones de calidad, etc.

    -   Comprobar su correlación con SalePrice para validarlas.

-   **Escalado**:

    -   Normalizar o estandarizar variables numéricas según el algoritmo y la magnitud de los valores.

-   **Validación**:

    -   Separar datos de entrenamiento y testantes de encodings y escalados, para no sobreajustar.

# Análisis de Grupos

## Estadistico de Hopkins

```{r groupingstup, echo=FALSE, warning=FALSE}
# 2. Lectura del dataset de viviendas (ajusta la ruta según corresponda)
datos <- read.csv("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/data/processed/train_preprocessed.csv", stringsAsFactors = FALSE)

# 3. Selección de variables relevantes para el clustering
# Se usan variables relacionadas con el precio, áreas, calidad y antigüedad
datos_clust <- datos %>% 
  select(SalePrice, GrLivArea, LotArea, OverallQual, YearBuilt, TotalBsmtSF, GarageArea)

# 4. Manejo de valores faltantes (eliminamos filas con NA en las variables seleccionadas)
datos_clust <- na.omit(datos_clust)

# 5. Transformación de variables con fuerte sesgo (aplicamos logaritmo)
datos_clust <- datos_clust %>%
  mutate(
    SalePrice_log    = log(SalePrice + 1),
    GrLivArea_log    = log(GrLivArea + 1),
    LotArea_log      = log(LotArea + 1),
    TotalBsmtSF_log  = log(TotalBsmtSF + 1),
    GarageArea_log   = log(GarageArea + 1)
  ) %>%
  # Seleccionamos las variables transformadas y las que no se transformaron
  select(SalePrice_log, GrLivArea_log, LotArea_log, OverallQual, YearBuilt, TotalBsmtSF_log, GarageArea_log)

# 6. Escalar las variables para que tengan el mismo peso
datos_scaled <- scale(datos_clust)
datos_scaled <- datos_scaled[apply(datos_scaled, 1, function(x) all(is.finite(x))), ]


```

```{r hopkins, echo=FALSE, warning=FALSE}
set.seed(123)
hopkins_stat <- hopkins(datos_clust)
print(paste("Hopkins statistic:", round(hopkins_stat, 4)))


```

El estadístico de Hopkins confirma una fuerte tendencia a clusterizar.

## VAT

```{r vat, echo=FALSE, warning=FALSE}
# Un valor cercano a 0.5 indicaría aleatoriedad; valores cercanos a 0 o 1 sugieren estructura (la interpretación depende del contexto)
# ---- Muestreo para análisis ----
# Seleccionar una muestra (por ejemplo, 1120 observaciones) para agilizar el cálculo
# Suponiendo que 'datos_scaled' ya está definido (datos procesados y escalados)
set.seed(123)
n_sample <- min(1120, nrow(datos_scaled))
datos_sample <- datos_scaled[sample(seq_len(nrow(datos_scaled)), n_sample), ]

# Calcular la matriz de distancias Euclideana usando parDist
datos_dist <- parDist(as.matrix(datos_sample), method = "euclidean")

# Confirmar que es de clase "dist"
print(class(datos_dist))  # Debe imprimir "dist"

# Convertir la matriz de distancias a matriz, normalizar y reconvertir a 'dist'
dist_matrix <- as.matrix(datos_dist)
dist_matrix_norm <- (dist_matrix - min(dist_matrix)) / (max(dist_matrix) - min(dist_matrix))
datos_dist_norm <- as.dist(dist_matrix_norm)

# Verificar el rango de distancias normalizadas
print(range(dist_matrix_norm))  # Debería ser 0 a 1

# Visualizar la matriz de distancias con fviz_dist (VAT)
plot_vat_sample <- fviz_dist(datos_dist_norm, 
                             show_labels = FALSE,
                             gradient = list(low = "#005D8F",    
                                             mid2 = "#5CC6FF",    
                                             mid3 = "#FFFFFF",     
                                             mid4 = "#E01522",    
                                             high = "#780000")) +  
  ggtitle("VAT sobre muestra de 1120 observaciones") +
  theme_minimal() +
  scale_fill_gradientn(
    colors = c("#005D8F", "#5CC6FF", "#FFFFFF", "#E01522", "#780000"),
    values = scales::rescale(c(
      quantile(as.matrix(datos_dist_norm), 0.01),  
      quantile(as.matrix(datos_dist_norm), 0.25),  
      quantile(as.matrix(datos_dist_norm), 0.75),  
      quantile(as.matrix(datos_dist_norm), 0.99)
    )),
    name = "Distancia"
  ) +
  theme(
    plot.title = element_text(size = 14, face = "bold"),
    axis.text = element_blank(),
    axis.title = element_blank(),
    legend.position = "right"
  )

# Mostrar la gráfica
print(plot_vat_sample)


```

Se observa que la matriz de distancias presenta una estructura clara, con bloques de observaciones similares en color blanco y líneas oscuras que separan grupos de observaciones. Esto sugiere que los datos tienen una estructura no aleatoria y son adecuados para el clustering.

## Número optimo de clusters (Método del Codo)

```{r elbow, echo=FALSE, warning=FALSE}


# Calcular el método del codo (WSS) utilizando la muestra
fviz_nbclust(datos_scaled, kmeans, method = "wss") +
  geom_vline(xintercept = 4, linetype = 2) +
  labs(subtitle = "Método del Codo")

```

La gráfica muestra que el codo se encuentra entre k=3 y k = 4, lo que sugiere que este es el número óptimo de clusters para el conjunto de datos.

## K-Means

### Agrupamiento con K=3

```{r kmeans, echo=FALSE, warning=FALSE}
library(knitr)
library(kableExtra)
datos_scaled <- as.data.frame(datos_scaled)

set.seed(123)
k <- 3
km_res <- kmeans(datos_scaled, centers = k, nstart = 25)

km_summary <- data.frame(
  Cluster = 1:k,
  Size = km_res$size,
  Tot_WithinSS = km_res$tot.withinss
)



kable(km_summary, caption = "Resumen General del Modelo K-means") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
# También puedes mostrar los centros de los clusters:
km_centers <- as.data.frame(round(km_res$centers, 3))
km_centers$Cluster <- rownames(km_centers)
kable(km_centers, caption = "Centros de los Clusters") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))



```

#### Visualización de Clusters

```{r clusterplot, echo=FALSE, warning=FALSE}

set.seed(123)
k <- 3
km_res <- kmeans(as.matrix(datos_scaled), centers = k, nstart = 25)

fviz_cluster(km_res, data = as.matrix(datos_scaled), ellipse.type = "convex",
             palette = "jco", ggtheme = theme_minimal(),
             main = "Clusters K-means (k = 3)")


```

### Agrupamiento con K=4

```{r kmeans2, echo=FALSE, warning=FALSE}
library(knitr)
library(kableExtra)

# Crear un resumen con el tamaño de cada cluster y la suma de cuadrados intra-grupo
set.seed(123)
k <- 4
km_res <- kmeans(datos_scaled, centers = k, nstart = 25)



kable(km_summary, caption = "Resumen General del Modelo K-means") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))

# También puedes mostrar los centros de los clusters:
km_centers <- as.data.frame(round(km_res$centers, 4))
km_centers$Cluster <- rownames(km_centers)
kable(km_centers, caption = "Centros de los Clusters") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))



```

#### Visualización de Clusters

```{r clusterplot2, echo=FALSE, warning=FALSE}



fviz_cluster(km_res, data = datos_scaled, ellipse.type = "convex",
             palette = "jco", ggtheme = theme_minimal(),
             main = "Clusters K-means (k = 4)")





```

```{r plotclst2 , echo = FALSE, warning = FALSE}
set.seed(123)
n_sample <- min(85, nrow(datos_scaled))
idx <- sample(seq_len(nrow(datos_scaled)), n_sample)
df_sub <- datos_scaled[idx, ]

# Aplicar K-means a la muestra
km3_sub <- kmeans(df_sub, centers = 3, nstart = 25)


cluster_plot3 <- fviz_cluster(km3_sub,
                              data = df_sub,
                              geom = "point",         # Representa cada punto
                              ellipse.type = "norm",  # Elipses basadas en la varianza
                              main = "Clusters (k = 3)")

set.seed(123)
km4_sub <- kmeans(df_sub, centers = 4, nstart = 25)
cluster_plot4 <- fviz_cluster(km4_sub,
                              data = df_sub,
                              geom = "point",
                              ellipse.type = "norm",
                              main = "Clusters (k = 4)")

library(gridExtra)
grid.arrange(cluster_plot3, cluster_plot4, ncol = 2)


```

```{r clustloc, echo=FALSE, warning=FALSE}


library(gridGraphics)
library(gridExtra)

# Seleccionar una muestra (por ejemplo, 85 observaciones)
set.seed(123)
n_sample <- min(85, nrow(datos_scaled))
idx <- sample(seq_len(nrow(datos_scaled)), n_sample)
df_sub <- datos_scaled[idx, ]

## Gráfico para k = 3
set.seed(123)
km3 <- kmeans(datos_scaled, centers = 3, nstart = 25)
clusters_sub3 <- km3$cluster[idx]

# Capturar el plot base para k=3
plot_k3 <- function(){
  plotcluster(as.matrix(df_sub), clusters_sub3, method = "dc", clnum = TRUE, 
              main = "Ubicación de los Clusters (k = 3)")
}
# Preparar y capturar el gráfico
grid.newpage()
grid.echo(plot_k3)
p3 <- grid.grab()

## Gráfico para k = 4
set.seed(123)
km4 <- kmeans(datos_scaled, centers = 4, nstart = 25)
clusters_sub4 <- km4$cluster[idx]

# Capturar el plot base para k=4
plot_k4 <- function(){
  plotcluster(as.matrix(df_sub), clusters_sub4, method = "dc", clnum = TRUE, 
              main = "Ubicación de los Clusters (k = 4)")
}
grid.newpage()
grid.echo(plot_k4)
p4 <- grid.grab()

# Combinar los dos gráficos en una sola imagen
grid.arrange(p3, p4, ncol = 2)


```

-   El modelo con 3 clusters agrupa el mercado de viviendas en tres segmentos (alta, media, baja) de forma razonable y más sencilla.

-   El modelo con 4 clusters incrementa la separación estadística y reduce la variabilidad interna, pero añade complejidad en la interpretación. La elección final depende tanto de la validez estadística como de la utilidad práctica para el análisis o toma de decisiones .

-   Con 4 clusters se logra una mayor segmentación del mercado, dividiendo uno de los grupos grandes en dos.

## Calidad del Agrupamiento

```{r silhouette, echo=FALSE, warning=FALSE}

# Para k = 3
set.seed(123)
km3 <- kmeans(datos_scaled, centers = 3, nstart = 25)
sil3 <- silhouette(km3$cluster, dist(datos_scaled))
p_sil3 <- fviz_silhouette(sil3) + labs(title = "Gr\u00E1fico de Silueta (k = 3)")

# Para k = 4
set.seed(123)
km4 <- kmeans(datos_scaled, centers = 4, nstart = 25)
sil4 <- silhouette(km4$cluster, dist(datos_scaled))
p_sil4 <- fviz_silhouette(sil4) + labs(title = "Gr\u00E1fico de Silueta (k = 4)")

# Visualizar ambos gráficos lado a lado
library(gridExtra)
grid.arrange(p_sil3, p_sil4, ncol = 2)

```

```{r silhouette2, echo=FALSE, warning=FALSE}

library(dplyr)
library(cluster)

# Supongamos que 'df_numeric' es tu dataframe numérico (ya procesado y escalado)
# Si aún no lo tienes, asegúrate de crearlo a partir de tus datos procesados.

set.seed(123)
n_sample <- 85
df_sample <- datos_scaled %>% sample_n(n_sample)

# Para k = 3
km3 <- kmeans(df_sample, centers = 3, iter.max = 100, nstart = 25)
silkm3 <- silhouette(km3$cluster, dist(df_sample))
silhouette_promedio3 <- mean(silkm3[, 3])
cat("Silhouette promedio (k = 3):", silhouette_promedio3, "\n")

# Para k = 4
km4 <- kmeans(df_sample, centers = 4, iter.max = 100, nstart = 25)
silkm4 <- silhouette(km4$cluster, dist(df_sample))
silhouette_promedio4 <- mean(silkm4[, 3])
cat("Silhouette promedio (k = 4):", silhouette_promedio4, "\n")

# Graficar la silueta para ambas soluciones
par(mfrow = c(1, 2))  # Configura la gráfica en 2 columnas
plot(silkm3, cex.names = 0.8, col = 1:6, main = "Análisis de la Silueta - k = 3")
plot(silkm4, cex.names = 0.8, col = 1:6, main = "Análisis de la Silueta - k = 4")


```

Ambas configuraciones (k=3 y k=4) muestran un promedio de silueta, bajo. Esto indica que:

1.  La separación entre clusters no es muy marcada (hay solapamiento).

2.  Con k=4 aparece un cluster pequeño que mejora su silueta, pero otro obtiene valores muy bajos, compensando el beneficio.

3.  En términos globales, no hay una gran diferencia en la calidad de la segmentación entre 3 y 4 clusters.

En resumen, los datos sugieren que la estructura de los clusters no está fuertemente definida o que tal vez se necesiten otras técnicas (por ejemplo, reducción de dimensionalidad o índices adicionales) para encontrar una segmentación más clara.

## Análisis de Componentes Principales (PCA)

### Mátriz de Correlación

```{r pca, echo=FALSE, warning=FALSE}

# Cargar el dataset de entrenamiento
datostrain <- read.csv("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/data/processed/train_preprocessed.csv", stringsAsFactors = FALSE)

# Seleccionar las variables numéricas relevantes para PCA
pca_vars <- c("SalePrice", "GrLivArea", "LotArea", "OverallQual", "YearBuilt", "TotalBsmtSF", "GarageArea")
pca_data <- datostrain %>% select(one_of(pca_vars)) %>% na.omit()

# Escalar los datos
pca_data_scaled <- scale(pca_data)

# Calcular y visualizar la matriz de correlación
cor_matrix <- cor(pca_data_scaled)
det_cor <- det(cor_matrix)
cat("Determinante de la matriz de correlacion:", round(det_cor, 5), "\n")
corrplot(cor_matrix, method = "color", addCoef.col = "black", number.cex = 0.7, tl.cex = 0.8)

```

```{r corrpca3, echo = FALSE, warning = FALSE}

# Calcular la matriz de correlación
cor_matrix <- cor(pca_data_scaled, use = "pairwise.complete.obs")

# Calcular el determinante de la matriz de correlación
det_val <- det(cor_matrix)



# Imprimir el determinante de la matriz
knitr::asis_output(paste("\n### Determinante de la Matriz de Correlación: ", round(det_val, 5), "\n"))
```

Observervamos que el determinante de la matriz de correlación es cercano a 0, lo que indica que las variables están altamente correlacionadas, lo cual es un requisito para aplicar PCA.

La matriz de correlación confirma que la calidad y el tamaño (habitable, sótano, garaje) son los principales impulsores del precio de venta de las viviendas, mientras que la antigüedad y el área del lote tienen un papel secundario

### Indice de Kaiser-Meyer-Olkin (KMO)

```{r kmo, echo=FALSE, warning=FALSE}

# Índice KMO y test de esfericidad de Bartlett
kmo_result <- KMO(pca_data_scaled)
kmo_df <- data.frame(
  `Índice KMO Global` = round(kmo_result$MSA, 4)
)

kable(kmo_df, caption = "Índice de Kaiser-Meyer-Olkin (KMO) Global") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))



```

### Test de esfericidad de Bartlett

```{r bartlett, echo = FALSE, warning = FALSE}
library(psych)  # Cargar la librería necesaria

# Seleccionar solo variables numéricas del dataset escalado

# Aplicar el test de Bartlett
bartlett_result <- cortest.bartlett(pca_data_scaled)

# Formatear la salida como tabla
bartlett_df <- data.frame(
  `Chi-cuadrado` = round(bartlett_result$chisq, 4),
  `Grados de Libertad` = bartlett_result$df,
  `p-valor` = round(bartlett_result$p.value, 10)
)

kable(bartlett_df, caption = "Test de Esfericidad de Bartlett") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))


```

El índice KMO es mayor a 0.5 y el test de Bartlett es significativo con un p-valor = 0 , indicando que las variables están efectivamente correlacionadas., lo que indica que los datos son adecuados para realizar un análisis de componentes principales.

### Análisis de Componentes Principales

```{r pca2, echo=FALSE, warning=FALSE}
# Realizar el PCA
pca_res <- prcomp(pca_data_scaled, center = TRUE, scale. = TRUE)
# Obtener el resumen del PCA
pca_summary <- summary(pca_res)

# Extraer la proporción de varianza explicada por cada componente
pca_var <- data.frame(
  Componente = paste0("PC", seq_along(pca_summary$importance[2,])),
  Proporción_Varianza = round(pca_summary$importance[2,] * 100, 2),  # Convertir a porcentaje
  Varianza_Acumulada = round(pca_summary$importance[3,] * 100, 2)  # Convertir a porcentaje
)

# Imprimir tabla con knitr
knitr::kable(pca_var, caption = "Proporción de Varianza Explicada por Componente") %>%
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))


```

### Regla de Kaiser

```{r kaiser, echo=FALSE, warning=FALSE}
# Calcular los valores propios del PCA
valores_propios <- pca_res$sdev^2

# Crear un dataframe con los valores propios
valores_propios_df <- data.frame(
  Componente = paste0("PC", seq_along(valores_propios)),
  Valor_Propio = round(valores_propios, 4)  # Redondeamos para mejor visualización
)

# Imprimir tabla con knitr
knitr::kable(valores_propios_df, caption = "Valores Propios de Cada Componente Principal") %>%
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))




```

Se retienen los primeros 2 componentes principales cumplen con este criterio, por lo que se retendrán para el análisis.

### Regla de Sedimentación

```{r pca3, echo=FALSE, warning=FALSE}
# Scree Plot - Porcentaje de varianza explicada
# Scree Plot con porcentaje de varianza explicada
fviz_eig(pca_res, addlabels = TRUE, ylim = c(0, 80)) +
  ggtitle("Scree Plot - Porcentaje de Varianza Explicada")

# Scree Plot con valores propios (Eigenvalues)
fviz_eig(pca_res, addlabels = TRUE, ylim = c(0, 4), choice = "eigenvalue") +
  ggtitle("Scree Plot - Valores Propios")

```

Gran parte de la variabilidad se concentra en la primera y segunda componente, y que la tercera todavía aporta una porción apreciable. Más allá de la tercera, las ganancias en varianza explicada son mucho menores.

### Paralelismo de los Componentes Principales

```{r paralelismo, echo = FALSE, warning = FALSE}

library(paran)

# Aplicar el análisis de paralelismo
paran_result <- paran(pca_data_scaled, graph = TRUE, centile = 95)

# Agregar título a la gráfica
title("Análisis de Paralelismo - Evaluación de Componentes Principales")

```

El analisis sugiere conservar 2 componentes principales, ya que la tercera (y siguientes) no se diferencian lo bastante de los valores propios generados al azar.

### Carga Factorial

```{r carga, echo = FALSE, warning = FALSE}

# Visualizar la importancia de las variables en los componentes principales
fviz_pca_var(pca_res, 
             col.var = "cos2",  # Colorear según calidad de representación
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), 
             repel = TRUE)  # Evitar superposición de etiquetas


```

-   La primera componente (Dim1) captura la mayor parte de la información relevante para el valor de la casa (tamaño, calidad, precio).

-   La segunda componente aporta un matiz adicional (por ejemplo, tamaño de lote y antigüedad), pero su peso en la varianza total es menor.

-   Variables como SalePrice, OverallQual, GrLivArea, TotalBsmtSF y GarageArea se mueven en conjunto, reforzando la idea de que la calidad y los espacios construidos son factores clave en la determinación del precio de venta.

#### Contribución de Variables en las primeras dimensiones

```{r contrib, echo = FALSE, warning = FALSE}
fviz_contrib(pca_res, choice = "var", axes = 1, top = 10)


```

```{r contrib2, echo = FALSE, warning = FALSE}
fviz_contrib(pca_res, choice = "var", axes = 2, top = 10)



```

```{r contrib3, echo = FALSE, warning = FALSE}
# Obtener la matriz de cos² de las variables en el PCA
var <- get_pca_var(pca_res)

# Visualizar la matriz de cos²
corrplot(var$cos2, is.corr = FALSE, 
         col = colorRampPalette(c("white", "#00AFBB", "#E7B800", "#FC4E07"))(200),
         tl.col = "black", tl.srt = 45, 
         title = "Calidad de Representación de Variables (cos²)", 
         mar = c(1, 1, 2, 1))




```

-   La dimension 1 es la dimensión principal en la cual se conentran relaciones de precio,calidad espacios de las casas.

-   La segunda dimensión explica fáctores como el tamaño del lote y la antiguedad de la vivienda que no presentan una relación tan significativa con el precio como la primera.

-   El análisis de **contribución** y **cos²** refuerza que, en el espacio de las dos primeras componentes, se distinguen claramente dos ejes interpretables:

    -   Eje 1: Valor/Calidad/Tamaño construidos

    -   Eje 2: Tamaño de lote/Año de construcción

# Modelado Predictivo (Regresión lineal)

Se separan los datos en conjuntos de entrenamiento y testeo,y se aplica un modelo de regresión lineal para predecir el precio de venta de las viviendas.

```{r modeladoSTP, echo=FALSE, warning=FALSE}

library(dplyr)
library(ggplot2)
library(caret)      # Para partición y evaluación
library(car)        # Para calcular VIF y detectar multicolinealidad
library(nortest)    # Para pruebas de normalidad de residuos
library(glmnet)     # Para Ridge y Lasso
library(tidyr)      # Para reorganizar datos (si es necesario)
library(GGally)     # Para matriz de dispersión
library(corrplot)
library(tibble)

datostrain <- read.csv("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/data/processed/train_preprocessed.csv", stringsAsFactors = FALSE)
datostest <- read.csv("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/data/processed/test_preprocessed.csv", stringsAsFactors = FALSE)

```

```{r modeladoSTP2, echo=FALSE, warning=FALSE}
library(knitr)
tabla_filas <- data.frame(
  Dataset = c("Entrenamiento", "Prueba"),
  Filas = c(nrow(datostrain), nrow(datostest))
)
kable(tabla_filas, caption = "Número de filas en cada dataset")



```

## Modelo Univariado

Se trabaja con la variable más correlacionada con el precio de venta: GrLivArea.

```{r modeladoSTP3, echo=FALSE, warning=FALSE}
library(broom)
library(knitr)
modelo_uni <- lm(SalePrice ~ GrLivArea, data = datostrain)

tabla_modelo <- tidy(modelo_uni)
kable(tabla_modelo, caption = "Resumen del Modelo Lineal")




```

GrLivArea es un predictor muy fuerte en el modelo, mientras que el intercepto no aporta información relevante.

### Representación Gráfica

```{r modeladounigraph, echo=FALSE, warning=FALSE}

ggplot(datostrain, mapping= aes(x = GrLivArea, y = SalePrice)) +
  geom_point(color = "firebrick", alpha = 0.6) +
  geom_smooth(method = "lm", se = TRUE, color = "black") +
  labs(title = "Regresión Lineal Univariada: SalePrice ~ GrLivArea",
       x = "GrLivArea", y = "SalePrice`") +
  theme_bw()+ theme(plot.title = element_text(hjust = 0.5))

```

La gráfica muestra una relación lineal positiva entre el área habitable y el precio de venta, con una dispersión considerable en los datos.

### Residuos

```{r residuosuni, echo=FALSE, warning=FALSE}

# Generar predicciones para el conjunto de entrenamiento (o el que corresponda)
predL <- predict(modelo_uni, newdata = datostrain)

library(knitr)
# Tabla de las primeras predicciones
tabla_pred <- data.frame(Predicciones = head(predL))
kable(tabla_pred, caption = "Primeras Predicciones")

# Tabla de los primeros residuales
tabla_res <- data.frame(Residuales = head(modelo_uni$residuals))
kable(tabla_res, caption = "Primeros Residuales")

# Número total de predicciones
kable(data.frame(Total = length(predL)), caption = "Número total de predicciones")

```

```{r residuosuni2, echo=FALSE, warning=FALSE}

par(mfrow = c(2, 2))
plot(modelo_uni)
par(mfrow = c(1, 1))

```

-   **Residuals vs Fitted**:

    -   Muestra cómo se distribuyen los residuos en función de las predicciones. No se aprecia un patrón en “U” o “∩” muy marcado, aunque se observan algunos puntos alejados.

-   **Q-Q Residuals**:

    -   Varios puntos siguen la línea teórica, pero se observa **cierta desviación** en colas.

    -   Indica que la distribución de los residuos se aleja de la normalidad en los valores más altos y más bajos.

-   **Scale-Location**:

    -   No se ve un patrón muy pronunciado, pero sí algo de dispersión variable.

-   **Residuals vs Leverage**:

    -   Algunas observaciones podrían tener un impacto desproporcionado en el ajuste.

#### Distribución de Residuos

```{r residuosuni3, echo=FALSE, warning=FALSE}


hist(modelo_uni$residuals, breaks = 30, col = "lightblue", border = "black", main = "Histograma de Residuos", xlab = "Residuos")

```

```{r residuosuni4, echo=FALSE, warning=FALSE}
boxplot(modelo_uni$residuals, col = "lightblue", border = "black", main = "Boxplot de Residuos")


```

-   **Histograma**: Los residuos se concentran mayoritariamente alrededor de 0, con cola a la izquierda y derecha.

-   **Boxplot**: Hay valores atípicos tanto por debajo como por encima. La mediana está cerca de 0.

```{r residuosuni5, echo=FALSE, warning=FALSE}

qqnorm(modelo_uni$residuals, col = "blue", pch = 20, main = "Gráfico Q-Q de Residuos")
qqline(modelo_uni$residuals, col = "red")

```

#### Prueba de Normalidad

```{r residuosuni6, echo=FALSE, warning=FALSE}
library(nortest)
resultado_lillie <- lillie.test(modelo_uni$residuals)

# Crear la tabla usando solo los elementos disponibles (estadístico y p_value)
tabla_lillie <- data.frame(
  Estadístico = as.numeric(resultado_lillie$statistic),
  p_value = resultado_lillie$p.value
)

library(knitr)
kable(tabla_lillie, caption = "Resultado del Test de Lilliefors")

```

### Predicción y Ecualización

```{r preduni, echo=FALSE, warning=FALSE}
library(knitr)

pred_uni <- predict(modelo_uni, newdata = datostest)
head(pred_uni)
rmse_uni <- RMSE(pred_uni, datostest$SalePrice)
cat("RMSE del modelo univariado:", rmse_uni, "\n")


```

#### Gráfico de Predicciones

```{r preduni2, echo=FALSE, warning=FALSE}
#Grafico de la predicción
plot(datostest$SalePrice, col = "blue")
points(pred_uni, col = "red")




```

```{r preduni3, echo=FALSE, warning=FALSE}
resumen_diff <- summary(datostest$SalePrice - pred_uni)
tabla_resumen <- data.frame(
  Estadística = names(resumen_diff),
  Valor = as.vector(resumen_diff)
)
library(knitr)
kable(tabla_resumen, caption = "Resumen de la diferencia (SalePrice - pred_uni)")


```

1.  **Relación significativa**: GrLivArea tiene un efecto fuertemente positivo y significativo en SalePrice.

2.  **Intercepto no significativo**: No aporta gran información cuando GrLivArea = 0.

3.  **Distribución de residuos**:

    -   La media y mediana de (SalePrice - Predicción) están cercanas a 0, lo que sugiere que no hay un sesgo sistemático.

    -   Existen puntos outlier y el test de Lilliefors indica **no normalidad** de los residuos.

    -   Aun así, el modelo univariado capta la tendencia global: a mayor área habitable, mayor precio.

En suma, la **regresión univariada** SalePrice \~ GrLivArea **confirma** que el área habitable es un predictor relevante y explica una parte importante de la variabilidad en el precio de las viviendas, pero **no** captura toda la complejidad del problema.

## Modelo Multivariado (Todas las Variables numéricas)

```{r modeladoSTP4, echo=FALSE, warning=FALSE}
library(dplyr)
library(ggplot2)
library(caret)      # Para partición y evaluación
library(car)        # Para calcular VIF y detectar multicolinealidad
library(nortest)    # Para pruebas de normalidad de residuos
library(glmnet)     # Para Ridge y Lasso
library(tidyr)      # Para reorganizar datos (si es necesario)
library(GGally)     # Para matriz de dispersión
library(corrplot)
library(tibble)


```

### Selección de Variables

```{r multirlstp, echo=FALSE, warning=FALSE}
datostrain <- read.csv("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/data/processed/train_preprocessed.csv", stringsAsFactors = FALSE)
datostest <- read.csv("C:/Users/rodri/Documents/Data-Mining/DM-Proyecto-2/data/processed/test_preprocessed.csv", stringsAsFactors = FALSE)


names(datostrain) <- make.names(names(datostrain))
names(datostest)  <- make.names(names(datostest))

# 2. Seleccionar todas las variables numéricas en cada conjunto
num_vars_train <- names(datostrain)[sapply(datostrain, is.numeric)]
num_vars_test  <- names(datostest)[sapply(datostest, is.numeric)]

```

Se seleccionan todas las vaariables numericas del dataset. Sin embargo, por motivos de visualizacion se escojen aquellas con mayor correlación para el calculo de la mátriz de correlación variables que presentan la mayor relación de acuerdo a la mátriz de correlación.

```{r multirlstp2, echo=FALSE, warning=FALSE}

common_vars <- intersect(num_vars_train, num_vars_test)
tabla_common <- data.frame(Variables = common_vars)
library(knitr)
kable(tabla_common, caption = "Variables numéricas comunes")

if(!"SalePrice" %in% common_vars) {
  stop("La variable 'SalePrice' no se encuentra en los datos numéricos comunes.")
}
vars_seleccionadas <-  c("SalePrice",   # Variable objetivo
                         "GrLivArea", 
                         "LotArea",
                         "OverallQual",
                         "YearBuilt",
                         "TotalBsmtSF",
                         "GarageArea")
pairs(datostrain[, vars_seleccionadas], main = "Matriz de Dispersión Reducida")


```

```{r multirlstp4, echo=FALSE, warning=FALSE}

matriz_corrpairs <- cor(datostrain[, vars_seleccionadas])
matriz_corrpairs

corrplot(matriz_corrpairs)


```

Definimos los predictores

```{r multirlstp5, echo=FALSE, warning=FALSE}

predictors <- setdiff(common_vars, "SalePrice")
tabla_predictors <- data.frame(Predictor = predictors)
library(knitr)
kable(tabla_predictors, caption = "Predictores seleccionados")

```

```{r multirlstp6, echo=FALSE, warning=FALSE}
# Definir la fórmula del modelo
formula_numeric <- as.formula(paste("SalePrice ~", paste(predictors, collapse = " + ")))

# Filtrar los conjuntos de datos para las variables de interés
train_filtered <- datostrain[, c("SalePrice", predictors)]
train_filtered <- train_filtered[complete.cases(train_filtered), ]
test_filtered  <- datostest[, c("SalePrice", predictors)]
test_filtered  <- test_filtered[complete.cases(test_filtered), ]

# Convertir la fórmula a texto y mostrarla en una tabla
formula_text <- deparse(formula_numeric)
tabla_formula <- data.frame(Formula = formula_text)
library(knitr)
kable(tabla_formula, caption = "Fórmula del modelo")

# Crear tabla con las dimensiones de los conjuntos filtrados
tabla_dims <- data.frame(
  Conjunto = c("train_filtered", "test_filtered"),
  Filas = c(nrow(train_filtered), nrow(test_filtered)),
  Columnas = c(ncol(train_filtered), ncol(test_filtered))
)
kable(tabla_dims, caption = "Dimensiones de los conjuntos filtrados")



```

```{r multirlstp7, echo=FALSE, warning=FALSE}

library(broom)
library(knitr)
model_multi <- lm(SalePrice ~ ., data = train_filtered)

tabla_model_multi <- tidy(model_multi)
kable(tabla_model_multi, caption = "Resumen del Modelo Lineal Múltiple")

```

### Analisis de Residuos

```{r multirlstp8, echo=FALSE, warning=FALSE}


par(mfrow = c(2, 2))
plot(model_multi)
par(mfrow = c(1, 1))
```

#### Histograma de Residuos

```{r multirlstp9, echo=FALSE, warning=FALSE}
hist(model_multi$residuals, breaks = 30, col = "lightblue", border = "black", main = "Histograma de Residuos", xlab = "Residuos")


```

#### Boxplot de Residuos

```{r multirlstp10, echo=FALSE, warning=FALSE}

boxplot(model_multi$residuals, col = "lightblue", border = "black", main = "Boxplot de Residuos")


```

### Pruaba de Normalidad

```{r multirlstp11, echo=FALSE, warning=FALSE}
lillie_result <- lillie.test(model_multi$residuals)
print(lillie_result)

```

### Predicción y Ecualización

```{r multirlstp12, echo=FALSE, warning=FALSE}
pred_test <- predict(model_multi, newdata = test_filtered)
rmse_multi <- RMSE(pred_test, test_filtered$SalePrice)
cat("RMSE del modelo multivariado en test:", rmse_multi, "\n")



```

```{r multirlstp13, echo=FALSE, warning=FALSE}
plot(test_filtered$SalePrice, col = "blue")
points(pred_test, col = "red")

```

```{r multirlstp14, echo=FALSE, warning=FALSE}
resumen_diff_multi <- summary(test_filtered$SalePrice - pred_test)
# Forzar nombres estándar si no están disponibles
nombres_estandar <- c("Min", "1st Qu.", "Median", "Mean", "3rd Qu.", "Max")
tabla_resumen_multi <- data.frame(
  Estadística = nombres_estandar,
  Valor = as.numeric(resumen_diff_multi)
)
library(knitr)
kable(tabla_resumen_multi, caption = "Resumen de la diferencia (SalePrice - pred_test)")



```

### Análisis de Errores

```{r multirlstp15, echo=FALSE, warning=FALSE}
prediccion_train <- predict(model_multi, newdata = train_filtered)
prediccion_test <- predict(model_multi, newdata = test_filtered)

train_mse <- mean((prediccion_train - train_filtered$SalePrice)^2)
test_mse <- mean((prediccion_test - test_filtered$SalePrice)^2)

tabla_mse <- data.frame(
  Conjunto = c("Entrenamiento", "Prueba"),
  MSE = c(train_mse, test_mse)
)
library(knitr)
kable(tabla_mse, caption = "MSE en Entrenamiento y Prueba")

```

**Análisis del Modelo y Detección de Multicolinealidad**

-   **Multicolinealidad:**\
    Al ajustar el modelo completo se observa que algunas variables están fuertemente correlacionadas, lo que puede generar coeficientes inestables y altos errores estándar. La matriz de correlación y gráficos de dispersión confirman estas relaciones.

-   **Variables Relevantes:**\
    Mediante análisis de correlación y la significancia en el resumen del modelo, se identificaron aquellas variables que aportan de manera significativa . Sin embargo, la inclusión de todas puede introducir redundancia.

**2. Adaptación del Modelo y Sobreajuste**

-   **Ajuste al Dataset:**\
    Aunque el modelo completo muestra un R² alto , el análisis de residuos evidencia patrones y falta de normalidad en los residuos, lo que sugiere que el modelo no captura toda la complejidad y podría estar sobreajustado.

-   **Sobreajuste (Overfitting):**\
    Se observa que el error de entrenamiento es significativamente menor que el error en el conjunto de prueba, lo que indica que el modelo completo podría estar ajustándose demasiado a los datos de entrenamiento.

## Modelo Normalizado

```{r modeladoSTP5, echo=FALSE, warning=FALSE}
train_filtered_norm <- as.data.frame(scale(train_filtered))
test_filtered_norm <- as.data.frame(scale(test_filtered))

model_multi_norm <- lm(SalePrice ~ ., data = train_filtered_norm)
library(broom)
library(knitr)
tabla_model_multi_norm <- tidy(model_multi_norm)
kable(tabla_model_multi_norm, caption = "Resumen del Modelo Lineal Múltiple (Normalizado)")


```

```{r modeladoSTP6, echo=FALSE, warning=FALSE}
par(mfrow = c(2, 2))
plot(model_multi_norm)
par(mfrow = c(1, 1))

```

Seleccionamos predictores

```{r modeladoSTP7, echo=FALSE, warning=FALSE}


library(broom)
library(knitr)
modelo_mult2  <- step(
 object = lm(formula = SalePrice ~ ., data = train_filtered),
 direction = "backward",
 scope = list(upper = ~ ., lower = ~ 1),
 trace = FALSE
)
tabla_modelo_mult2 <- tidy(modelo_mult2)
kable(tabla_modelo_mult2, caption = "Resumen del Modelo Multivariado (Stepwise Backward)")

```

### Test de Normalidad

```{r modeladoSTP8, echo=FALSE, warning=FALSE}

lillie.test(modelo_mult2$residuals)

```

### Predicción y Ecualización

```{r modeladoSTP9, echo=FALSE, warning=FALSE}

prediccion_train2 <- predict(modelo_mult2, newdata = train_filtered)
prediccion_test2 <- predict(modelo_mult2, newdata = test_filtered)

train_stepwise <- mean((prediccion_train2 - train_filtered$SalePrice)^2)
test_stepwise_mse <- mean((prediccion_test2 - test_filtered$SalePrice)^2)


tabla_stepwise <- data.frame(
  Conjunto = c("Entrenamiento", "Prueba"),
  MSE = c(train_stepwise, test_stepwise_mse)
)
library(knitr)
kable(tabla_stepwise, caption = "MSE del Modelo Stepwise Backward en Entrenamiento y Prueba")


```

```{r modeladoSTP10, echo=FALSE, warning=FALSE}
plot(test_filtered$SalePrice, col = "blue")
points(prediccion_test2, col = "red")


```

-   **Motivación y Efecto de la Normalización:**

    -   Todas las variables se escalan a media 0 y desviación estándar 1.

    -   Los coeficientes se vuelven directamente comparables: un coeficiente más grande indica mayor impacto relativo sobre el precio.

-   **Principales Hallazgos en los Coeficientes:**

    -   Variables como *OverallQual*, *OverallCond*, *YearBuilt*, *LotArea* y *TotalBsmtSF* muestran coeficientes positivos y muy significativos.

    -   Muchas otras variables presentan p-valores altos, sugiriendo que su aporte es menor o está solapado por predictores más fuertes.

-   **Residuos y Ajuste del Modelo:**

    -   Los gráficos de diagnóstico (Residuals vs Fitted, Q-Q) revelan patrones y desviaciones en las colas, indicando no normalidad de residuos.

    -   El test de Lilliefors confirma p-valor cercano a 0, por lo que se rechaza la hipótesis de normalidad.

    -   La alta dimensionalidad y varias variables con poca significancia sugieren posible sobreajuste.

-   **Conclusión:**

    -   El modelo normalizado facilita comparar la importancia relativa de cada predictor, pero no resuelve problemas de residuos ni sobreajuste.

## Modelos Regularizados

## Modelo Ridge

Se crean las matrices de entrenamiento y testeo, y y se ajusta un modelo de regresión Ridge. La regularización de los coeficientes evita el sobreajuste y mejorar la generalización del modelo.

```{r modeladoSTP1sss0, echo=FALSE, warning=FALSE}

x_train <- model.matrix(SalePrice ~ ., data = train_filtered)[, -1]
y_train <- train_filtered$SalePrice

x_test <- model.matrix(SalePrice ~ ., data = test_filtered)[, -1]
y_test <- test_filtered$SalePrice
model_ridge <- glmnet(x = x_train, y = y_train, alpha = 0, nlambda = 100, standardize = TRUE)
regularization <- model_ridge$beta %>% as.matrix() %>% t() %>% as.tibble() %>% mutate(lambda = model_ridge$lambda)
regularization  <- regularization %>% pivot_longer(cols = -lambda, names_to = "predictor", values_to = "coefficients")


regularization %>% 
  ggplot(aes(x = lambda, y = coefficients, color = predictor)) +
  geom_line() +
  labs(title = "Coeficientes del modelo en función de la regularizacion") +
  theme_bw() +
  theme(legend.position = "none")

```

Se determina el valor óptimo de lambda mediante validación cruzada y se ajusta el modelo final.

```{r modeladoSTP11, echo=FALSE, warning=FALSE}
cv_error <- cv.glmnet(
  x      = x_train,
  y      = y_train,
  alpha  = 0,
  nfolds = 10,
  type.measure = "mse",
  standardize  = TRUE
)

# imprimir el valor óptimo de lambda con kable
tabla_lambda <- data.frame(
  Lambda_Optimo = cv_error$lambda.min,
  MSE_CV = cv_error$cvm[cv_error$lambda == cv_error$lambda.min]
)
kable(tabla_lambda, caption = "Valor óptimo de lambda y MSE en validación cruzada")
```

```{r modeladoSTP12, echo=FALSE, warning=FALSE}


plot(cv_error)

```

Se establece un modelo con el valor óptimo de lambda y se evalua su desempeño en el conjunto de testeo.

```{r modeladoSTP13, echo=FALSE, warning=FALSE}
model3 <- glmnet(x = x_train, y = y_train, alpha = 0, lambda = cv_error$lambda.1se, standardize = TRUE)


```

```{r modeladoSTP14, echo=FALSE, warning=FALSE}
# Convertir los coeficientes a una matriz densa y luego a data.frame
coef_model3 <- coef(model3)
tabla_coef <- as.data.frame(as.matrix(coef_model3))
tabla_coef$Coeficiente <- rownames(tabla_coef)
colnames(tabla_coef)[1] <- "Valor"
tabla_coef <- tabla_coef[, c("Coeficiente", "Valor")]

library(knitr)
kable(tabla_coef, caption = "Coeficientes del Modelo 3")


```

Se observan las predicciones y se calcula el error cuadrático medio en el conjunto de testeo.

```{r modeladoSTsP15, echo=FALSE, warning=FALSE}
## Grafica de predicciones

pred_train_model3 <- predict(model3,newx = x_train)
plot(test_filtered$SalePrice, col = "blue")
points(pred_train_model3, col = "red")

```

```{r modeladoSTP15, echo=FALSE, warning=FALSE}

pred_train_model3 <- predict(model3,newx = x_train)

pred_test_model3 <- predict(model3,newx = x_test)


test_mse_model3 <- mean((pred_test_model3 - y_test)^2)
cat("MSE en prueba:", test_mse_model3, "\n")

cat("MSE en entrenamiento:", mean((pred_train_model3 - y_train)^2), "\n")


```

-   Elección de lambda Óptimo

    -   Se aplicó validación cruzada para determinar el valor de 0.0756, que balancea la complejidad del modelo (penalizando los coeficientes) y su capacidad de predicción.

-   Coeficientes Suavizados

    -   A diferencia del modelo OLS, Ridge reduce la magnitud de todos los coeficientes sin llegar a anularlos.

    -   Variables importantes (e.g., *OverallQual*, *GrLivArea*, *TotalArea*, *TotalBsmtSF*) conservan coeficientes positivos y relativamente altos, pero atenuados frente a un modelo sin penalización.

-   **Desempeño y Generalización**

    -   **MSE de Entrenamiento**: \~0.1225

    -   **MSE de Prueba**: \~0.1203

    -   La similitud entre ambos errores indica que el modelo **no está sobreajustado**, y la regularización contribuye a una mejor estabilidad frente a multicolinealidad.

-   **Conclusiones**

    -   Ridge reduce la varianza y mejora la robustez del modelo al encoger los coeficientes.

    -   El error de prueba y entrenamiento son cercanos, lo que evidencia una buena generalización.

## Modelo Lasso

Se construye un modelo Lasso y ajustamos los coeficientes mediante validación cruzada.

```{r modeladoSTP16, echo=FALSE, warning=FALSE}

model_lasso <- glmnet(x = x_train, y = y_train, alpha = 1, nlambda = 100, standardize = TRUE)

regularization_lasso <- model_lasso$beta %>% as.matrix() %>% t() %>% as.tibble() %>% mutate(lambda = model_lasso$lambda)

regularization_lasso  <- regularization_lasso %>% pivot_longer(cols = !lambda, names_to = "predictor", values_to = "coefficients")


regularization_lasso %>% 
  ggplot(aes(x = lambda, y = coefficients, color = predictor)) +
  geom_line() +
  labs(title = "Coeficientes del modelo en función de la regularización") +
  theme_bw() +
  theme(legend.position = "none")



```

Se determina el valor óptimo de lambda mediante validación cruzada y ajustamos el modelo final.

```{r modeladoSTP17, echo=FALSE, warning=FALSE}
cv_error_lasso <- cv.glmnet(
  x      = x_train,
  y      = y_train,
  alpha  = 1,
  nfolds = 10,
  type.measure = "mse",
  standardize  = TRUE
)

plot(cv_error_lasso)


```

El valor óptimo de lambda y el error cuadrático medio en validación cruzada son:

```{r modeladoSTP18, echo=FALSE, warning=FALSE}
print(cv_error_lasso)


```

Ahora ajustamos el modelo con el valor óptimo de lambda y evaluamos su desempeño en el conjunto de testeo.

```{r modeladoSTP19, echo=FALSE, warning=FALSE}
model_lasso <- glmnet(x = x_train, y = y_train, alpha = 1, lambda = cv_error_lasso$lambda.1se, standardize = TRUE)

coef(model_lasso)

```

Se determinan los predictores con los coeficientes no nulos y evaluamos el modelo en el conjunto de testeo.

Se obtienen 18 predictores con coeficientes no nulos.

El error cuadrático medio en el conjunto de testeo es de:

```{r modeladoSTP20, echo=FALSE, warning=FALSE}

pred_train_model_lasso <- predict(model_lasso,newx = x_train)

pred_test_model_lasso <- predict(model_lasso,newx = x_test)


test_mse_model_lasso <- mean((pred_test_model_lasso - y_test)^2)

train_mse_model_lasso <- mean((pred_train_model_lasso - y_train)^2)

cat("MSE en prueba:", test_mse_model_lasso, "\n")

cat("MSE en entrenamiento:", train_mse_model_lasso, "\n")

```

```{r modeladoplt1, echo=FALSE, warning=FALSE}
plot(test_filtered$SalePrice, col = "blue")
points(pred_test_model_lasso, col = "red")



```

**Análisis del Modelo Lasso**

-   Elección del lambda Óptimo

    -   Se usó validación cruzada (10 folds) para estimar el error cuadrático medio (MSE) a diferentes valores de lambda

    -   De los resultados, se destacan dos valores de lambda:

        -   lambda minimo​: aquel que minimiza el MSE en validación cruzada (\~0.00869).

        -   lambda1se​: el más sencillo dentro de 1 desviación estándar del mínimo (\~0.03851).

-   **Coeficientes No Nulos**

    -   Lasso tiende a poner en cero muchos coeficientes, quedándose con un subconjunto reducido de predictores (18 en este caso).

    -   Entre las variables seleccionadas sobresalen:

        -   **OverallQual** (coef. \~0.24), **GrLivArea** (\~0.26), **TotalArea** (\~0.17) y **KitchenQual** (\~0.05).

        -   Algunas variables importantes en OLS (como *TotalBsmtSF* o *GarageArea*) quedan en cero si su aporte marginal no supera la penalización.

-   **Desempeño Predictivo**

    -   **MSE en Entrenamiento**: \~0.1082

    -   **MSE en Prueba**: \~0.1080

    -   La cercanía de estos errores indica buena generalización y ausencia de sobreajuste significativo.

    -   El modelo final es más simple, pues sólo 18 predictores quedan con coeficientes distintos de cero.

-   **Conclusiones**

    -   Reduce la complejidad del modelo, dejando un número manejable de variables relevantes.

    -   Error de prueba y entrenamiento similares, lo que evidencia buena capacidad de generalización.

    -   Algunas variables potencialmente útiles pueden ser forzadas a cero si su efecto es relativamente menor frente a la penalización.

    -   Puede omitirse información marginalmente significativa.

## Comparación de Modelos

```{r modeladoSTP21, echo=FALSE, warning=FALSE}

modelos <- c( "Multivariado", "Multivariado Normalizado", "Multivariado Stepwise", "Ridge", "Lasso")
mse <- c( test_mse, test_mse, test_stepwise_mse, test_mse_model3, test_mse_model_lasso)
ggplot(data = data.frame(modelos, mse), aes(x = modelos, y = mse)) +
  geom_col(fill = "lightblue", color = "black") +
  geom_text(aes(label = round(mse, 2)), vjust = -0.5) +
  labs(title = "Comparación de Modelos", x = "Modelo", y = "MSE") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


```

Calculo de AIC y BIC para los modelos

```{r modeladoSTP22, echo=FALSE, warning=FALSE}

glmnet_cv_aicc <- function(fit) {
  # 'fit' es el objeto glmnet ajustado (por ejemplo, model3 o model_lasso)
  # tLL: diferencia entre la nula y la deviance actual
  tLL <- fit$nulldev - deviance(fit)
  # k: número de predictores en cada lambda (vector)
  k <- fit$df
  # n: número de observaciones
  n <- fit$nobs
  
  # AICc para cada lambda
  AICc <- -tLL + 2 * k + (2 * k * (k + 1)) / (n - k - 1)
  
  # BIC para cada lambda
  BIC <- log(n) * k - tLL
  
  # Retornar como lista
  list(AICc = AICc, BIC = BIC)
}

##################################################
# 2. Calcular AIC y BIC para el modelo lineal
##################################################
aic_linear <- AIC(model_multi)
bic_linear <- BIC(model_multi)

#aic stepwise

aic_stepwise <- AIC(modelo_mult2)
bic_stepwise <- BIC(modelo_mult2)


##################################################
# 3. Calcular AICc y BIC para Ridge y Lasso
##################################################
# Nota: glmnet produce un vector de lambdas. 
# La función glmnet_cv_aicc() devuelve un vector de AICc y BIC 
# para cada lambda en 'fit$lambda'.

aic_bic_ridge <- glmnet_cv_aicc(model3)     # model3 es tu modelo Ridge
aic_bic_lasso <- glmnet_cv_aicc(model_lasso) # model_lasso es tu modelo Lasso

# Si deseas elegir un lambda en particular (por ejemplo, el lambda.1se),
# convendría extraer la posición del lambda en 'model3$lambda' y tomar
# la AICc/BIC correspondiente.

# Por ejemplo, si ya usaste 'model3 <- glmnet(..., lambda = cv_error$lambda.1se)',
# 'model3$lambda' es un solo valor. 
# Si, en cambio, usaste nlambda = 100, tendrás 100 lambdas.

# Supongamos que en 'model3' solo hay un lambda. 
# Entonces aic_bic_ridge$AICc y aic_bic_ridge$BIC serán vectores de longitud 1 (o más).
# Toma el primer valor si es uno solo:
ridge_aicc <- aic_bic_ridge$AICc[1]
ridge_bic  <- aic_bic_ridge$BIC[1]

lasso_aicc <- aic_bic_lasso$AICc[1]
lasso_bic  <- aic_bic_lasso$BIC[1]

##################################################
# 4. Crear un data frame con la comparación
##################################################
dfMetricas <- data.frame(
  Modelo = c("Lineal Múltiple", "Stepwise", "Ridge", "Lasso"),
  AIC_or_AICc = c(aic_linear, aic_stepwise, ridge_aicc, lasso_aicc),
  BIC = c(bic_linear, bic_stepwise, ridge_bic, lasso_bic)
)


dfMetricas

```

-   **Modelo Stepwise**

    -   **Ventaja:** El MSE más bajo (0.09) en el conjunto de prueba.

    -   **Inconveniente:** Su AIC/BIC no es tan bueno como el de los modelos regularizados (Ridge, Lasso).

    -   **Uso recomendado:** Si la prioridad es la **precisión de predicción** y no se penaliza tanto la complejidad.

-   **Modelo Lasso**

    -   **Ventaja:** Logra un MSE razonablemente bajo (0.11) y la mejor puntuación en AIC/BIC. Además, selecciona un número reducido de variables.

    -   **Uso recomendado:** Cuando se busca simplicidad y un buen balance entre ajuste y complejidad según criterios de información.

-   **Modelo Ridge**

    -   **Ventaja:** Estabiliza coeficientes frente a multicolinealidad, con MSE de 0.12.

    -   **Inconveniente:** No alcanza ni el MSE más bajo ni el mejor AIC/BIC.

    -   **Uso recomendado:** Situaciones con alta correlación entre predictores donde se desee mantener **todos** los coeficientes.

-   **Modelo OLS Completo y Normalizado**

    -   Ambos tienen MSE \~0.10, relativamente buenos, pero un AIC/BIC elevado , lo que sugiere mayor complejidad de la necesaria y potencial riesgo de sobreajuste.

Por ende en el caso de la predicción de precios de casas en el mercado inmobiliario tanto los modelos regularizados y la selección de variables pueden llegar a brindar el equilibrio necesario entre la calidad de interpretar con precisión. En este caso, se usa la predicción del modelo Stepwise dado que fue el que tuvo un mejor desempeño en comparación a los demas.

```{r modeladoSTP23, echo=FALSE, warning=FALSE}


plot(test_filtered$SalePrice, col = "blue",main = "Predicciones vs valores reales")
points(prediccion_test2, col = "red")
legend("topright", legend = c("Real", "Predicción"), col = c("blue", "red"), pch = 1)


summary
```
